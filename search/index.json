[{"content":"参考: https://www.cnblogs.com/pandabang/p/10441242.html\n  音量大/小：CTRL+上/下\n  静音开/关：M\n  回退/快进：ALT+左/右（步进10s），CTRL+左/右（步进1min）\n  跳到指定时间：CTRL+T\n  播放/暂停：空格\n  停止播放：S（与暂停不同，按下停止后播放进度条回到视频最开始，且窗口不显示视频；而暂停时，窗口显示暂停时的视频）\n  播放速度：{或- 减慢，最慢速度0.02倍正常速度；} 加速，最快速度31.25倍正常速度； = 正常速度\n  全屏开/关：F\n  纵横比切换：A（默认、16:9、4:3、1:1、16:10、2.21:1、2:35:1、2.39:1、5:4）\n  窗口尺寸切换：Z（¼、½、原始尺寸、2倍原始尺寸）\n  显示播放时间/总时长：T\n  播放控件显示/不显示：CTRL+H\n  ","date":"2022-09-04T16:25:18+08:00","permalink":"https://mkbooks.github.io/blog/p/vlc%E6%92%AD%E6%94%BE%E5%99%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","title":"VLC播放器快捷键"},{"content":"多方连接测试 1: Party-9999和Party-10000\n在A集群的Master机器操作\n1 2 3 4 5 6 7 8 9  kubectl get pods -n fate-9999 | grep client 返回 client-5fcd4fdcfd-nqvrz 1/1 Running 0 2d1h 获取client容器ID kubectl exec -it client-5fcd4fdcfd-nqvrz -n fate-9999 bash flow test toy -gid 9999 -hid 10000   3: Party-10000和Party-9999\n在C集群的Master机器操作\n1 2 3 4 5 6 7 8 9 10  kubectl get pods -n fate-10000 | grep client 返回 client-845c4df74-xbf89 1/1 Running 0 47h 获取client容器ID kubectl exec -it client-845c4df74-xbf89 -n fate-10001 bash flow test toy -gid 10000 -hid 9999   成功显示结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  toy test job 202205090852477671460 is waiting toy test job 202205090852477671460 is waiting toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is running toy test job 202205090852477671460 is success [INFO] [2022-05-09 08:52:53,088] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:96]: begin to init parameters of secure add example guest [INFO] [2022-05-09 08:52:53,088] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:100]: begin to make guest data [INFO] [2022-05-09 08:52:53,136] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:103]: split data into two random parts [INFO] [2022-05-09 08:52:54,031] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:106]: share one random part data to host [INFO] [2022-05-09 08:52:54,035] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:109]: get share of one random part data from host [INFO] [2022-05-09 08:52:54,573] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:112]: begin to get sum of guest and host [INFO] [2022-05-09 08:52:54,645] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:115]: receive host sum from guest [INFO] [2022-05-09 08:52:54,721] [202205090852477671460] [1339:139984863901504] - [secure_add_guest.run] [line:122]: success to calculate secure_sum, it is 2000.0000000000002   6.9.5.2 多方训练测试 如何两两之间互通测试通过，我们就可以跑一个三方的test_hetero_lr来测试多方的任务训练。\ntest_hetero_lr的任务需要三方参与，Guest，Host和Arbiter。我们将Party-9999作为Guest，Party-10000作为Host和Arbiter。\n1：在Party-10000上传 host 方数据集\n1 2 3 4 5 6 7 8 9 10  kubectl get pods -n fate-10000 | grep client 返回 client-64f7959ff5-7hvt9 1/1 Running 0 2d 获取client容器ID kubectl exec -it client-64f7959ff5-7hvt9 -n fate-10000 bash 上传数据 flow data upload -c fateflow/examples/upload/upload_host.json   2：在Party-9999上传 guest 方数据集\n1 2 3 4 5 6 7 8 9 10  kubectl get pods -n fate-9999 | grep client 返回 client-5fcd4fdcfd-nqvrz 1/1 Running 0 2d1h 获取client容器ID kubectl exec -it client-5fcd4fdcfd-nqvrz -n fate-9999 bash 上传数据 flow data upload -c fateflow/examples/upload/upload_guest.json   3：在Party-9999发起训练任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118  kubectl get pods -n fate-9999 | grep client 返回 client-5fcd4fdcfd-nqvrz 1/1 Running 0 2d1h 获取client容器ID kubectl exec -it client-5fcd4fdcfd-nqvrz -n fate-9999 bash 修改文件 cat \u0026gt; fateflow/examples/lr/test_hetero_lr_job_conf.json \u0026lt;\u0026lt;EOF { \u0026#34;dsl_version\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;initiator\u0026#34;: { \u0026#34;role\u0026#34;: \u0026#34;guest\u0026#34;, \u0026#34;party_id\u0026#34;: 10004 }, \u0026#34;role\u0026#34;: { \u0026#34;guest\u0026#34;: [ 10004 ], \u0026#34;host\u0026#34;: [ 10001 ], \u0026#34;arbiter\u0026#34;: [ 10001 ] }, \u0026#34;job_parameters\u0026#34;: { \u0026#34;common\u0026#34;: { \u0026#34;task_parallelism\u0026#34;: 2, \u0026#34;computing_partitions\u0026#34;: 8, \u0026#34;task_cores\u0026#34;: 4, \u0026#34;auto_retries\u0026#34;: 1 } }, \u0026#34;component_parameters\u0026#34;: { \u0026#34;common\u0026#34;: { \u0026#34;intersection_0\u0026#34;: { \u0026#34;intersect_method\u0026#34;: \u0026#34;raw\u0026#34;, \u0026#34;sync_intersect_ids\u0026#34;: true, \u0026#34;only_output_key\u0026#34;: false }, \u0026#34;hetero_lr_0\u0026#34;: { \u0026#34;penalty\u0026#34;: \u0026#34;L2\u0026#34;, \u0026#34;optimizer\u0026#34;: \u0026#34;rmsprop\u0026#34;, \u0026#34;alpha\u0026#34;: 0.01, \u0026#34;max_iter\u0026#34;: 3, \u0026#34;batch_size\u0026#34;: 320, \u0026#34;learning_rate\u0026#34;: 0.15, \u0026#34;init_param\u0026#34;: { \u0026#34;init_method\u0026#34;: \u0026#34;random_uniform\u0026#34; } } }, \u0026#34;role\u0026#34;: { \u0026#34;guest\u0026#34;: { \u0026#34;0\u0026#34;: { \u0026#34;reader_0\u0026#34;: { \u0026#34;table\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;breast_hetero_guest\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;experiment\u0026#34; } }, \u0026#34;dataio_0\u0026#34;: { \u0026#34;with_label\u0026#34;: true, \u0026#34;label_name\u0026#34;: \u0026#34;y\u0026#34;, \u0026#34;label_type\u0026#34;: \u0026#34;int\u0026#34;, \u0026#34;output_format\u0026#34;: \u0026#34;dense\u0026#34; } } }, \u0026#34;host\u0026#34;: { \u0026#34;0\u0026#34;: { \u0026#34;reader_0\u0026#34;: { \u0026#34;table\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;breast_hetero_host\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;experiment\u0026#34; } }, \u0026#34;dataio_0\u0026#34;: { \u0026#34;with_label\u0026#34;: false, \u0026#34;output_format\u0026#34;: \u0026#34;dense\u0026#34; }, \u0026#34;evaluation_0\u0026#34;: { \u0026#34;need_run\u0026#34;: false } } } } } } EOF 发起训练任务 flow job submit -d fateflow/examples/lr/test_hetero_lr_job_dsl.json -c fateflow/examples/lr/test_hetero_lr_job_conf.json 返回结果 { \u0026#34;data\u0026#34;: { \u0026#34;board_url\u0026#34;: \u0026#34;http://fateboard:8080/index.html#/dashboard?job_id=202208310748436341990\u0026amp;role=guest\u0026amp;party_id=10001\u0026#34;, \u0026#34;code\u0026#34;: 0, \u0026#34;dsl_path\u0026#34;: \u0026#34;/data/projects/fate/fateflow/jobs/202208310748436341990/job_dsl.json\u0026#34;, \u0026#34;job_id\u0026#34;: \u0026#34;202208310748436341990\u0026#34;, \u0026#34;logs_directory\u0026#34;: \u0026#34;/data/projects/fate/fateflow/logs/202208310748436341990\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;model_info\u0026#34;: { \u0026#34;model_id\u0026#34;: \u0026#34;arbiter-9006#guest-10001#host-9006#model\u0026#34;, \u0026#34;model_version\u0026#34;: \u0026#34;202208310748436341990\u0026#34; }, \u0026#34;pipeline_dsl_path\u0026#34;: \u0026#34;/data/projects/fate/fateflow/jobs/202208310748436341990/pipeline_dsl.json\u0026#34;, \u0026#34;runtime_conf_on_party_path\u0026#34;: \u0026#34;/data/projects/fate/fateflow/jobs/202208310748436341990/guest/10001/job_runtime_on_party_conf.json\u0026#34;, \u0026#34;runtime_conf_path\u0026#34;: \u0026#34;/data/projects/fate/fateflow/jobs/202208310748436341990/job_runtime_conf.json\u0026#34;, \u0026#34;train_runtime_conf_path\u0026#34;: \u0026#34;/data/projects/fate/fateflow/jobs/202208310748436341990/train_runtime_conf.json\u0026#34; }, \u0026#34;jobId\u0026#34;: \u0026#34;202208310748436341990\u0026#34;, \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;success\u0026#34; }   4：命令查看任务结果\n1  flow task query -r guest -j 202208310748436341990 | grep -w f_status   6.9.6 联邦推理测试 上面已经基于hetero_lr进行多方训练，训练出模型，下面基于上面的多方训练后部署模型、加载模型、绑定模型、模型推理\n6.9.6.1 部署模型 进入party-9999容器内\n1 2 3 4 5 6 7  kubectl get pods -n fate-9999 | grep client 返回 client-5fcd4fdcfd-nqvrz 1/1 Running 0 2d1h 获取client容器ID kubectl exec -it client-5fcd4fdcfd-nqvrz -n fate-9999 bash   部署模型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  flow model deploy --model-id arbiter-10000#guest-9999#host-10000#model --model-version 202205180944078730290(任务ID) 返回 { \u0026#34;data\u0026#34;: { \u0026#34;arbiter\u0026#34;: { \u0026#34;9006\u0026#34;: 0 }, \u0026#34;detail\u0026#34;: { \u0026#34;arbiter\u0026#34;: { \u0026#34;9006\u0026#34;: { \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;deploy model of role arbiter 9006 success\u0026#34; } }, \u0026#34;guest\u0026#34;: { \u0026#34;10001\u0026#34;: { \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;deploy model of role guest 10001 success\u0026#34; } }, \u0026#34;host\u0026#34;: { \u0026#34;9006\u0026#34;: { \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;deploy model of role host 9006 success\u0026#34; } } }, \u0026#34;guest\u0026#34;: { \u0026#34;10001\u0026#34;: 0 }, \u0026#34;host\u0026#34;: { \u0026#34;9006\u0026#34;: 0 }, \u0026#34;model_id\u0026#34;: \u0026#34;arbiter-9006#guest-10001#host-9006#model\u0026#34;, \u0026#34;model_version\u0026#34;: \u0026#34;202208310755426963170\u0026#34; }, \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;success\u0026#34; }   获取到的信息是\n1 2  \u0026#34;model_id\u0026#34;: \u0026#34;arbiter-9006#guest-10001#host-9006#model\u0026#34;, \u0026#34;model_version\u0026#34;: \u0026#34;202208310755426963170\u0026#34;   6.9.6.2 加载模型 修改publish_load_model.json如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  cat \u0026gt; fateflow/examples/model/publish_load_model.json \u0026lt;\u0026lt;EOF { \u0026#34;initiator\u0026#34;: { \u0026#34;party_id\u0026#34;: \u0026#34;10001\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;guest\u0026#34; }, \u0026#34;role\u0026#34;: { \u0026#34;guest\u0026#34;: [ \u0026#34;10001\u0026#34; ], \u0026#34;host\u0026#34;: [ \u0026#34;10004\u0026#34; ], \u0026#34;arbiter\u0026#34;: [ \u0026#34;10004\u0026#34; ] }, \u0026#34;job_parameters\u0026#34;: { \u0026#34;model_id\u0026#34;: \u0026#34;arbiter-10004#guest-10001#host-10004#model\u0026#34;, \u0026#34;model_version\u0026#34;: \u0026#34;202209010444329886110\u0026#34; } } EOF   加载模型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  flow model load -c fateflow/examples/model/publish_load_model.json 返回信息 { \u0026#34;data\u0026#34;: { \u0026#34;detail\u0026#34;: { \u0026#34;guest\u0026#34;: { \u0026#34;10001\u0026#34;: { \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;success\u0026#34; } }, \u0026#34;host\u0026#34;: { \u0026#34;9006\u0026#34;: { \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;success\u0026#34; } } }, \u0026#34;guest\u0026#34;: { \u0026#34;10001\u0026#34;: 0 }, \u0026#34;host\u0026#34;: { \u0026#34;9006\u0026#34;: 0 } }, \u0026#34;jobId\u0026#34;: \u0026#34;202208310757075993710\u0026#34;, \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;success\u0026#34; }   6.9.6.3 绑定模型 修改版定模型配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  cat \u0026gt; fateflow/examples/model/bind_model_service.json \u0026lt;\u0026lt;EOF { \u0026#34;service_id\u0026#34;: \u0026#34;201\u0026#34;, \u0026#34;initiator\u0026#34;: { \u0026#34;party_id\u0026#34;: \u0026#34;10001\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;guest\u0026#34; }, \u0026#34;role\u0026#34;: { \u0026#34;guest\u0026#34;: [\u0026#34;10001\u0026#34;], \u0026#34;host\u0026#34;: [\u0026#34;10004\u0026#34;], \u0026#34;arbiter\u0026#34;: [\u0026#34;10004\u0026#34;] }, \u0026#34;job_parameters\u0026#34;: { \u0026#34;work_mode\u0026#34;: 1, \u0026#34;model_id\u0026#34;: \u0026#34;arbiter-10004#guest-10001#host-10004#model\u0026#34;, \u0026#34;model_version\u0026#34;: \u0026#34;202209010444329886110\u0026#34; } } EOF   绑定模型\n1 2 3 4 5 6 7  flow model bind -c fateflow/examples/model/bind_model_service.json 返回信息 { \u0026#34;retcode\u0026#34;: 0, \u0026#34;retmsg\u0026#34;: \u0026#34;service id is test03\u0026#34; }   6.9.6.4 联邦推理 配置party-10000的ingressHost\n1 2 3 4 5 6  sudo vi /etc/hosts 增加一行 10.0.1.199 9999.serving-proxy.sj.pclab 10.0.1.199 为partry-9999所在集群的Master节点IP，请根据集群IP进行修改   6.9.6.4.1 单笔推理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  curl -X POST -H \u0026#39;Content-Type: application/json\u0026#39; -i \u0026#39;http://10004.serving-proxy.204.pclab/federation/v1/inference\u0026#39; --data \u0026#39;{ \u0026#34;head\u0026#34;: { \u0026#34;serviceId\u0026#34;: \u0026#34;204\u0026#34; }, \u0026#34;body\u0026#34;: { \u0026#34;featureData\u0026#34;: { \u0026#34;x0\u0026#34;: 1.88669, \u0026#34;x1\u0026#34;: -1.359293, \u0026#34;x2\u0026#34;: 2.303601, \u0026#34;x3\u0026#34;: 2.00137, \u0026#34;x4\u0026#34;: 1.307686 }, \u0026#34;sendToRemoteFeatureData\u0026#34;: { \u0026#34;phone_num\u0026#34;: \u0026#34;122222222\u0026#34; } } }\u0026#39;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  curl -X POST -H \u0026#39;Content-Type: application/json\u0026#39; -i \u0026#39;http://10001.serving-proxy.sh.com/federation/v1/inference\u0026#39; --data \u0026#39;{ \u0026#34;head\u0026#34;: { \u0026#34;serviceId\u0026#34;: \u0026#34;201\u0026#34; }, \u0026#34;body\u0026#34;: { \u0026#34;featureData\u0026#34;: { \u0026#34;x0\u0026#34;: 1.88669, \u0026#34;x1\u0026#34;: -1.359293, \u0026#34;x2\u0026#34;: 2.303601, \u0026#34;x3\u0026#34;: 2.00137, \u0026#34;x4\u0026#34;: 1.307686 }, \u0026#34;sendToRemoteFeatureData\u0026#34;: { \u0026#34;phone_num\u0026#34;: \u0026#34;122222222\u0026#34; } } }\u0026#39;   返回\n1  {\u0026#34;retcode\u0026#34;:0,\u0026#34;retmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;score\u0026#34;:0.9983544928940998,\u0026#34;modelId\u0026#34;:\u0026#34;guest#9999#arbiter-10000#guest-9999#host-10000#model\u0026#34;,\u0026#34;modelVersion\u0026#34;:\u0026#34;202205090912483804370\u0026#34;,\u0026#34;timestamp\u0026#34;:1652087899953},\u0026#34;flag\u0026#34;:0}   6.9.6.4.2 批量推理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  curl -X POST -H \u0026#39;Content-Type: application/json\u0026#39; -i \u0026#39;http://10004.serving-proxy.204.pclab/federation/v1/batchInference\u0026#39; --data \u0026#39;{ \u0026#34;head\u0026#34;: { \u0026#34;serviceId\u0026#34;: \u0026#34;204\u0026#34; }, \u0026#34;body\u0026#34;: { \u0026#34;batchDataList\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;featureData\u0026#34;: { \u0026#34;x0\u0026#34;: 1.88669, \u0026#34;x1\u0026#34;: -1.359293, \u0026#34;x2\u0026#34;: 2.303601, \u0026#34;x3\u0026#34;: 2.00137, \u0026#34;x4\u0026#34;: 1.307686 }, \u0026#34;sendToRemoteFeatureData\u0026#34;: { \u0026#34;device_id\u0026#34;: \u0026#34;aaaaa\u0026#34;, \u0026#34;phone_num\u0026#34;: \u0026#34;122222222\u0026#34; } }, { \u0026#34;index\u0026#34;: 1, \u0026#34;featureData\u0026#34;: { \u0026#34;x0\u0026#34;: 1.88669, \u0026#34;x1\u0026#34;: -1.359293, \u0026#34;x2\u0026#34;: 2.303601, \u0026#34;x3\u0026#34;: 2.00137, \u0026#34;x4\u0026#34;: 1.307686 }, \u0026#34;sendToRemoteFeatureData\u0026#34;: { \u0026#34;device_id\u0026#34;: \u0026#34;aaaaa\u0026#34;, \u0026#34;phone_num\u0026#34;: \u0026#34;122222222\u0026#34; } } ] } }\u0026#39;   返回\n1  {\u0026#34;retcode\u0026#34;:0,\u0026#34;retmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;modelId\u0026#34;:\u0026#34;guest#9999#arbiter-10000#guest-9999#host-10000#model\u0026#34;,\u0026#34;modelVersion\u0026#34;:\u0026#34;202205110759591171670\u0026#34;,\u0026#34;timestamp\u0026#34;:1652256064349},\u0026#34;flag\u0026#34;:0,\u0026#34;batchDataList\u0026#34;:[{\u0026#34;index\u0026#34;:0,\u0026#34;retcode\u0026#34;:0,\u0026#34;retmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;score\u0026#34;:0.3813935132948826}},{\u0026#34;index\u0026#34;:1,\u0026#34;retcode\u0026#34;:0,\u0026#34;retmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;score\u0026#34;:0.3813935132948826}}],\u0026#34;singleInferenceResultMap\u0026#34;:{\u0026#34;0\u0026#34;:{\u0026#34;index\u0026#34;:0,\u0026#34;retcode\u0026#34;:0,\u0026#34;retmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;score\u0026#34;:0.3813935132948826}},\u0026#34;1\u0026#34;:{\u0026#34;index\u0026#34;:1,\u0026#34;retcode\u0026#34;:0,\u0026#34;retmsg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;score\u0026#34;:0.3813935132948826}}}}%   ","date":"2022-08-31T15:27:18+08:00","permalink":"https://mkbooks.github.io/blog/p/kubefate%E8%AE%AD%E7%BB%83%E6%B5%8B%E8%AF%95/","title":"kubefate训练测试"},{"content":"Ubuntu 20.04 1 2  ip route show # more /etc/network/interfaces   安装 net-tools\n1 2 3 4  sudo apt install net-tools route -n netstat -r   安装 sudo apt install traceroute\n1 2  # 第一行就是自己的网关 traceroute www.baidu.com -s 100   CentOS 1  more /etc/sysconfig/network-scripts/ifcfg-eth0   ","date":"2022-08-28T16:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0-0001/","title":"网络学习-0001"},{"content":"1. 使两台机器通过交换机连通 1.1 网络结构：\n1.2 网络现状：机器一和机器二不通。\n1.3 原因分析：当前两台机器都是自动获取IP模式，但是交换机不分配IP。\n1.4 目标：机器一和机器二连通。\n1.5 操作：\n给机器一设置 IP 和子网掩码(不设置网关)：\n address: 192.168.0.10 netmask: 255.255.255.0  给机器二设置 IP 和子网掩码(不设置网关)：\n address: 192.168.0.11 netmask: 255.255.255.0  1 2 3  # 临时修改 # ifconfig 网卡名称 IP地址 netmask 子网掩码 sudo ifconfig eno2 192.168.0.11 netmask 255.255.255.0   1.6 测试连通:\n1 2  # 机器一 ping 192.168.0.11   1 2  # 机器二 ping 192.168.0.10   测试连通成功\n2. 使机器一 192.168.0.0/24 的网段，可以跟机器二的 192.168.3.0/24 的网段互通 1.2 网络结构：\n1.2 网络现状：机器一和机器二 192.168.0.11 的 IP 互相连通，机器一和机器二 192.168.3.34 的 IP 互相不通。\n1.3 原因分析：两个网段不通。\n1.4 目标：使机器一 192.168.0.0/24 的网段，可以跟机器二的 192.168.3.0/24 的网段互通。\n1.5 操作：\n机器一\n1  sudo route add -net 192.168.3.0 netmask 255.255.255.0 gw 192.168.0.11   机器二\n1 2  iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -d 192.168.3.0/24 -o wlo1 -j MASQUERADE iptables -t nat -A POSTROUTING -s 192.168.3.0/24 -d 192.168.0.0/24 -o eno2 -j MASQUERADE   机器三\n1  sudo route add -net 192.168.0.0 netmask 255.255.255.0 gw 192.168.3.34   1.6 测试连通:\n1 2  # 机器一 ping 192.168.3.102   1 2  # 机器三 ping 192.168.0.10   测试连通成功\n","date":"2022-08-28T16:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0-0001/","title":"网络学习-0001"},{"content":"Ubuntu 20.04 机器能连通内网及路由网关，但是上不了网 参考：https://www.cnblogs.com/tinkone/p/10498524.html\n1 2 3 4  cjx@cjx-0002:~$ ip route show default via 192.168.3.1 dev enp6s0 proto static metric 20100 169.254.0.0/16 dev enp6s0 scope link metric 1000 192.168.3.0/24 dev enp6s0 proto kernel scope link src 192.168.3.102 metric 100   解决：\n1 2 3 4  sudo nano /etc/systemd/resolved.conf #在 DNS 下添加： DNS=8.8.8.8   重启即可\n","date":"2022-08-28T16:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98/","title":"网络问题"},{"content":"master 测试 获取服务 IP 和端口\n1 2 3 4  k -n kube-fate get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE mariadb ClusterIP 10.43.102.139 \u0026lt;none\u0026gt; 3306/TCP 113d kubefate ClusterIP 10.43.147.93 \u0026lt;none\u0026gt; 8080/TCP 113d   查看集群状态\n1 2 3 4  curl 10.43.147.93:8080 {\u0026#34;msg\u0026#34;:\u0026#34;kubefate run Success\u0026#34;} curl sh.com(域名) {\u0026#34;msg\u0026#34;:\u0026#34;kubefate run Success\u0026#34;}   获取 token\n1 2 3 4 5 6 7 8 9 10 11  curl -X POST -H \u0026#39;Content-Type: application/json\u0026#39; -i \u0026#39;http://10.43.147.93:8080/v1/user/login\u0026#39; --data \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;admin\u0026#34; }\u0026#39; {\u0026#34;code\u0026#34;:200,\u0026#34;expire\u0026#34;:\u0026#34;2022-08-29T07:34:13Z\u0026#34;,\u0026#34;token\u0026#34;:\u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NTg0NTMsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc1NjY1M30.HIlE-j-RxufqOgS2G0n9zLnsNVWK-GdGyX1rJeX4ons\u0026#34;} curl -X POST -H \u0026#39;Content-Type: application/json\u0026#39; -i \u0026#39;http://sh.com/v1/user/login\u0026#39; --data \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;admin\u0026#34; }\u0026#39; {\u0026#34;code\u0026#34;:200,\u0026#34;expire\u0026#34;:\u0026#34;2022-08-29T08:10:55Z\u0026#34;,\u0026#34;token\u0026#34;:\u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjA2NTUsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc1ODg1NX0.UqBvGxFnP2OgRE1t73_OBUlE-_aTaCEn99GNtAGX-2o\u0026#34;}   获取集群详情\n1  curl -XGET -i 10.43.147.93:8080/v1/cluster/\\?all\\=false -H \u0026#39;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjA2NTUsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc1ODg1NX0.UqBvGxFnP2OgRE1t73_OBUlE-_aTaCEn99GNtAGX-2o\u0026#39;   在容器内访问(通过完全限定域名访问) 查看集群状态\n1 2  curl kubefate.kube-fate:8080 {\u0026#34;msg\u0026#34;:\u0026#34;kubefate run Success\u0026#34;}   获取 token\n1 2 3 4 5  curl -X POST -H \u0026#39;Content-Type: application/json\u0026#39; -i \u0026#39;kubefate.kube-fate:8080/v1/user/login\u0026#39; --data \u0026#39;{ \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;admin\u0026#34; }\u0026#39; {\u0026#34;code\u0026#34;:200,\u0026#34;expire\u0026#34;:\u0026#34;2022-08-29T08:58:55Z\u0026#34;,\u0026#34;token\u0026#34;:\u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjM1MzUsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc2MTczNX0.T7tRQvbzVCbZfOzZZx3d00xKNbPs2_8_cUwEFAWJPUo\u0026#34;}   获取集群详情\n1  curl -XGET -i kubefate.kube-fate:8080/v1/cluster/\\?all\\=false -H \u0026#39;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjM1MzUsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc2MTczNX0.T7tRQvbzVCbZfOzZZx3d00xKNbPs2_8_cUwEFAWJPUo\u0026#39;   获取集群详情\n1  curl -XGET -i kubefate.kube-fate:8080/v1/cluster/\\?all\\=false -H \u0026#39;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjM1MzUsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc2MTczNX0.T7tRQvbzVCbZfOzZZx3d00xKNbPs2_8_cUwEFAWJPUo\u0026#39;   获取集群详情\n1 2 3  curl -XGET -i kubefate.kube-fate:8080/v1/cluster/c610796c-e2a4-48cc-b7b3-e911cc4bb7dc -H \u0026#39;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjYwMDMsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc2NDIwM30.S5bcFEL9HURx8R9tB1A1JQFe8ggVy7vnWkzjCaSp-n0\u0026#39; curl -XGET -i kubefate.kube-fate:8080/v1/cluster/566f37e0-ca8b-4627-b48c-239e494ffaec -H \u0026#39;Authorization:Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NjE3NjYwMDMsImlkIjoiYWRtaW4iLCJvcmlnX2lhdCI6MTY2MTc2NDIwM30.S5bcFEL9HURx8R9tB1A1JQFe8ggVy7vnWkzjCaSp-n0\u0026#39;   ","date":"2022-08-28T16:27:18+08:00","permalink":"https://mkbooks.github.io/blog/p/kubefate-api/","title":"kubefate api"},{"content":"参考：https://blog.csdn.net/wxhcyy/article/details/107718794\n 下载安装文件  1 2  # 链接从官方找 wget https://www.python.org/ftp/python/3.6.8/Python-3.6.8.tar.xz   解压  1 2  export d_path=\u0026#39;\u0026#39; tar xf Python-3.6.8.tar.xz -C $d_path   安装  1 2 3 4  cd $d_path ./configure --prefix=$d_path/python3.6.8 make all make install   测试  1  $d_path/python3.6.8/python -V   ","date":"2022-08-26T16:27:18+08:00","permalink":"https://mkbooks.github.io/blog/p/linux-%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85-python/","title":"linux 系统，使用源码安装 Python"},{"content":"File -\u0026gt; Settings -\u0026gt; Project: project_name -\u0026gt; Project Interpreter -\u0026gt; Add\u0026hellip; -\u0026gt; Virtualenv Environment -\u0026gt; (配置) -\u0026gt; OK\nsource project_path/venv/bin/activate\n命令行 Installation\nTo install virtualenv via pip run:\n1  $ pip3 install virtualenv   Usage\nCreation of virtualenv:\n1  $ virtualenv -p python3 \u0026lt;desired-path\u0026gt;   Activate the virtualenv:\n1  $ source \u0026lt;desired-path\u0026gt;/bin/activate   Deactivate the virtualenv:\n1  $ deactivate   ","date":"2022-08-26T15:04:18+08:00","permalink":"https://mkbooks.github.io/blog/p/pycharm-%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/","title":"pycharm 项目配置虚拟环境"},{"content":"转载：https://juejin.cn/post/6844903602968854542\n设置记住密码（默认15分钟） 可以将你的密码缓存下来，只用输一次密码，以后都可以不用输入了。缺点就是密码都明文保存在 ~/.git-credential 文件中。\n1  git config --global credential.helper cache   如果想自己设置时间，可以使用以下命令：\n1  git config credential.helper \u0026#39;cache --timeout=3600\u0026#39;   这样就设置一个小时之后失效\n长期存储密码： 1  git config --global credential.helper store   增加远程地址的时候带上密码也是可以的。(推荐)\n1  http://yourname:password@git.oschina.net/name/project.git   补充：使用客户端也可以存储密码。\n如果你正在使用ssh而且想体验https带来的高速，那么你可以这样做： 切换到项目目录下 ：\n1  cd project/   移除远程ssh方式的仓库地址\n1  git remote rm origin   复制代码增加https远程仓库地址\n1  git remote add origin http://yourname:password@git.oschina.net/name/project.git   ","date":"2022-08-26T14:36:18+08:00","permalink":"https://mkbooks.github.io/blog/p/git-http%E6%96%B9%E5%BC%8F%E5%85%8D%E5%AF%86%E6%8F%90%E4%BA%A4/","title":"git http方式免密提交"},{"content":"A B C 192.168.10.1 192.168.10.10 192.168.50.10 192.168.50.1\nip netns exec A ip addr add 192.168.30.246/24 dev A-To-br-A-B ip netns exec B ip addr add 192.168.30.1/24 dev B-To-br-A-B ip netns exec B ip addr add 192.168.40.1/24 dev B-To-br-B-C ip netns exec C ip addr add 192.168.40.133/24 dev C-To-br-B-C\nip netns exec B ping 192.168.30.246 -c1 ip netns exec B ping 192.168.40.133 -c1\nip netns exec A ping 192.168.30.246 -c1 ip netns exec A ping 192.168.40.133 -c1\nip netns exec C ping 192.168.30.246 -c1 ip netns exec C ping 192.168.40.133 -c1\nip netns exec A ip route add 192.168.50.0/24 via 192.168.10.10 dev A-To-br-A-B ip netns exec A ip route add 192.168.40.0/24 via 192.168.30.1 dev A-To-br-A-B\nip netns exec C ip route add 192.168.10.0/24 via 192.168.50.10 dev C-To-br-B-C ip netns exec C ip route add 192.168.30.0/24 via 192.168.40.1 dev C-To-br-B-C\nip netns exec A ping 192.168.40.133 -c 1\n","date":"2022-08-25T01:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/ip-netns/","title":"ip-netns"},{"content":"Namespace Route LAB Target 三个NS中网卡地址都可以相互访问。\n关键在创建恰当的路由，使其路由可达。\nFollow Me Check Env Status 1 2  root@network-lab:~# ip netns list root@network-lab:~# brctl show   Create Bridge 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  brctl addbr br-A-B # add bridge ip link set br-A-B up # enable bridge brctl addbr br-B-C # add bridge ip link set br-B-C up # enable bridge root@network-lab:~# brctl show bridge name bridge id STP enabled interfaces br-A-B 8000.000000000000 no br-B-C 8000.000000000000 no root@network-lab:~# ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: ens192: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:50:56:ac:a4:9b brd ff:ff:ff:ff:ff:ff 3: br-A-B: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/ether 76:8b:e0:6a:27:f8 brd ff:ff:ff:ff:ff:ff 4: br-B-C: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/ether a6:64:8b:a7:4c:2c brd ff:ff:ff:ff:ff:ff   Create Net Namespace 1 2 3 4 5 6 7 8 9 10  root@network-lab:~# ip netns list ip netns add A ip netns add B ip netns add C root@network-lab:~# ip netns list C B A   NS Status \u0026amp;\u0026amp; Enable lo dev 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  root@network-lab:~# ip -c -all netns exec ip a netns: C 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 netns: B 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 netns: A 1: lo: \u0026lt;LOOPBACK\u0026gt; mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 root@network-lab:~# ip -c -all netns exec ip link set dev lo up netns: C netns: B netns: A root@network-lab:~# ip -c -all netns exec ip a netns: C 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever netns: B 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever netns: A 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever   Create Veth Pair \u0026amp;\u0026amp; Connect Bridge NetNS via Veth Pair 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118  # NS A =\u0026gt; br-A-B ip link add A-To-br-A-B type veth peer name br-A-B-To-A ip link set dev A-To-br-A-B netns A ip netns exec A ip link set A-To-br-A-B up ip link set dev br-A-B-To-A master br-A-B ip link set br-A-B-To-A up # NS B =\u0026gt; br-A-B ip link add B-To-br-A-B type veth peer name br-A-B-To-B ip link set dev B-To-br-A-B netns B ip netns exec B ip link set B-To-br-A-B up ip link set dev br-A-B-To-B master br-A-B ip link set br-A-B-To-B up # NS B =\u0026gt; br-B-C ip link add B-To-br-B-C type veth peer name br-B-C-To-B ip link set dev B-To-br-B-C netns B ip netns exec B ip link set B-To-br-B-C up ip link set dev br-B-C-To-B master br-B-C ip link set br-B-C-To-B up # NS C =\u0026gt; br-B-C ip link add C-To-br-B-C type veth peer name br-B-C-To-C ip link set dev C-To-br-B-C netns C ip netns exec C ip link set C-To-br-B-C up ip link set dev br-B-C-To-C master br-B-C ip link set br-B-C-To-C up root@network-lab:~# brctl show bridge name bridge id STP enabled interfaces br-A-B 8000.4e3feeec3e7c no br-A-B-To-A br-A-B-To-B br-B-C 8000.06c767a60064 no br-B-C-To-B br-B-C-To-C root@network-lab:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens192: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc mq state UP group default qlen 1000 link/ether 00:50:56:ac:a4:9b brd ff:ff:ff:ff:ff:ff inet 192.168.31.133/24 brd 192.168.31.255 scope global dynamic ens192 valid_lft 36981sec preferred_lft 36981sec inet6 fe80::250:56ff:feac:a49b/64 scope link valid_lft forever preferred_lft forever 3: br-A-B: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 4e:3f:ee:ec:3e:7c brd ff:ff:ff:ff:ff:ff inet6 fe80::748b:e0ff:fe6a:27f8/64 scope link valid_lft forever preferred_lft forever 4: br-B-C: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 06:c7:67:a6:00:64 brd ff:ff:ff:ff:ff:ff inet6 fe80::a464:8bff:fea7:4c2c/64 scope link valid_lft forever preferred_lft forever 19: br-A-B-To-A@if20: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master br-A-B state UP group default qlen 1000 link/ether 4e:3f:ee:ec:3e:7c brd ff:ff:ff:ff:ff:ff link-netns A inet6 fe80::4c3f:eeff:feec:3e7c/64 scope link valid_lft forever preferred_lft forever 21: br-A-B-To-B@if22: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master br-A-B state UP group default qlen 1000 link/ether be:e7:ef:32:94:6a brd ff:ff:ff:ff:ff:ff link-netns B inet6 fe80::bce7:efff:fe32:946a/64 scope link valid_lft forever preferred_lft forever 23: br-B-C-To-B@if24: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master br-B-C state UP group default qlen 1000 link/ether 06:c7:67:a6:00:64 brd ff:ff:ff:ff:ff:ff link-netns B inet6 fe80::4c7:67ff:fea6:64/64 scope link valid_lft forever preferred_lft forever 25: br-B-C-To-C@if26: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master br-B-C state UP group default qlen 1000 link/ether 32:e7:67:9e:8a:9b brd ff:ff:ff:ff:ff:ff link-netns C inet6 fe80::30e7:67ff:fe9e:8a9b/64 scope link valid_lft forever preferred_lft forever root@network-lab:~# ip -all netns exec ip -c a netns: C 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 26: C-To-br-B-C@if25: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 6e:5f:b1:c9:3c:09 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::6c5f:b1ff:fec9:3c09/64 scope link valid_lft forever preferred_lft forever netns: B 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 22: B-To-br-A-B@if21: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 7a:4e:72:0a:0c:99 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::784e:72ff:fe0a:c99/64 scope link valid_lft forever preferred_lft forever 24: B-To-br-B-C@if23: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 32:ac:2b:9c:82:3f brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::30ac:2bff:fe9c:823f/64 scope link valid_lft forever preferred_lft forever netns: A 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 20: A-To-br-A-B@if19: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 3e:6a:83:aa:96:23 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::3c6a:83ff:feaa:9623/64 scope link valid_lft forever preferred_lft forever   Eable IP Forword 1  ip netns exec B sysctl -w net.ipv4.conf.all.forwarding=1   Assign IP 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  ip netns exec A ip addr add 192.168.10.1/24 dev A-To-br-A-B ip netns exec B ip addr add 192.168.10.10/24 dev B-To-br-A-B ip netns exec B ip addr add 192.168.50.10/24 dev B-To-br-B-C ip netns exec C ip addr add 192.168.50.1/24 dev C-To-br-B-C root@network-lab:~# ip -all netns exec ip -c a netns: C 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 26: C-To-br-B-C@if25: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 6e:5f:b1:c9:3c:09 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.50.1/24 scope global C-To-br-B-C valid_lft forever preferred_lft forever inet6 fe80::6c5f:b1ff:fec9:3c09/64 scope link valid_lft forever preferred_lft forever netns: B 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 22: B-To-br-A-B@if21: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 7a:4e:72:0a:0c:99 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.10.10/24 scope global B-To-br-A-B valid_lft forever preferred_lft forever inet6 fe80::784e:72ff:fe0a:c99/64 scope link valid_lft forever preferred_lft forever 24: B-To-br-B-C@if23: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 32:ac:2b:9c:82:3f brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.50.10/24 scope global B-To-br-B-C valid_lft forever preferred_lft forever inet6 fe80::30ac:2bff:fe9c:823f/64 scope link valid_lft forever preferred_lft forever netns: A 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 20: A-To-br-A-B@if19: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 3e:6a:83:aa:96:23 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 192.168.10.1/24 scope global A-To-br-A-B valid_lft forever preferred_lft forever inet6 fe80::3c6a:83ff:feaa:9623/64 scope link valid_lft forever preferred_lft forever # check ip address  root@network-lab:~# ip netns exec B ping 192.168.10.1 -c1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. 64 bytes from 192.168.10.1: icmp_seq=1 ttl=64 time=0.030 ms --- 192.168.10.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.030/0.030/0.030/0.000 ms root@network-lab:~# ip netns exec B ping 192.168.50.1 -c1 PING 192.168.50.1 (192.168.50.1) 56(84) bytes of data. 64 bytes from 192.168.50.1: icmp_seq=1 ttl=64 time=0.118 ms --- 192.168.50.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.118/0.118/0.118/0.000 ms # A access C - BAD root@network-lab:~# ip netns exec A ping 192.168.50.1 -c1 ping: connect: Network is unreachable root@network-lab:~# ip netns exec A ip r 192.168.10.0/24 dev A-To-br-A-B proto kernel scope link src 192.168.10.1   Check Route 1 2 3 4 5 6 7 8 9 10 11  root@network-lab:~# ip --all netns exec ip r netns: C 192.168.50.0/24 dev C-To-br-B-C proto kernel scope link src 192.168.50.1 netns: B 192.168.10.0/24 dev B-To-br-A-B proto kernel scope link src 192.168.10.10 192.168.50.0/24 dev B-To-br-B-C proto kernel scope link src 192.168.50.10 netns: A 192.168.10.0/24 dev A-To-br-A-B proto kernel scope link src 192.168.10.1   Add Route Make A access C 如何新增路由？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # Tell A how to access C ip netns exec A ip route add 192.168.50.0/24 via 192.168.10.10 dev A-To-br-A-B # Tell C how to access A ip netns exec C ip route add 192.168.10.0/24 via 192.168.50.10 dev C-To-br-B-C root@network-lab:~# ip --all netns exec ip r netns: C 192.168.10.0/24 via 192.168.50.10 dev C-To-br-B-C 192.168.50.0/24 dev C-To-br-B-C proto kernel scope link src 192.168.50.1 netns: B 192.168.10.0/24 dev B-To-br-A-B proto kernel scope link src 192.168.10.10 192.168.50.0/24 dev B-To-br-B-C proto kernel scope link src 192.168.50.10 netns: A 192.168.10.0/24 dev A-To-br-A-B proto kernel scope link src 192.168.10.1 192.168.50.0/24 via 192.168.10.10 dev A-To-br-A-B # succeed root@network-lab:~# ip netns exec A ping 192.168.50.1 -c 1 PING 192.168.50.1 (192.168.50.1) 56(84) bytes of data. 64 bytes from 192.168.50.1: icmp_seq=1 ttl=63 time=0.054 ms --- 192.168.50.1 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.054/0.054/0.054/0.000 ms   ","date":"2022-08-25T01:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/ip-netns-ling/","title":"ip-netns-ling"},{"content":"sysctl -w net.ipv4.ip_forward=1 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 80 -j DNAT \u0026ndash;to-destination 192.168.3.63:80 iptables -t nat -A POSTROUTING -p tcp -d 192.168.3.63 \u0026ndash;dport 80 -j SNAT \u0026ndash;to-source 192.168.3.243\nsysctl -w net.ipv4.ip_forward=1 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 80 -j DNAT \u0026ndash;to-destination 172.17.0.2:80 iptables -t nat -A POSTROUTING -p tcp -d 172.17.0.2 \u0026ndash;dport 80 -j SNAT \u0026ndash;to-source 192.168.3.63\niptables -t nat -A PREROUTING -d 192.168.3.63 -p tcp \u0026ndash;dport 80 -j DNAT \u0026ndash;to-destination 172.17.0.2:80 iptables -t nat -A POSTROUTING -d 172.17.0.2 -p tcp \u0026ndash;dport 80 -j SNAT \u0026ndash;to 192.168.3.63\nB: iptables -t nat -A POSTROUTING -s 192.168.3.0/24 -d 172.17.0.0/24 -o docker0 -j MASQUERADE iptables -t nat -A POSTROUTING -s 172.17.0.0/24 -d 192.168.3.0/24 -o enp0s3 -j MASQUERADE\nA: route add -net 172.17.0.0 netmask 255.255.255.0 gw 192.168.3.63\nC: route add -net 192.168.5.0 netmask 255.255.255.0 gw 192.168.3.63\necho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward B: iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -d 192.168.122.0/24 -o virbr0 -j MASQUERADE iptables -t nat -A POSTROUTING -s 192.168.122.0/24 -d 192.168.100.0/24 -o virbr1 -j MASQUERADE\nA: iptables -t nat -A POSTROUTING -s 192.168.122.0/24 -d 192.168.100.0/24 -o enp1s0 -j MASQUERADE\nroute add -net 192.168.100.0 netmask 255.255.255.0 gw 192.168.122.1 enp1s0\nC: route add -net 192.168.122.0 netmask 255.255.255.0 gw 192.168.100.1 enp1s0\nA: route add -net 192.168.100.0 netmask 255.255.255.0 gw 192.168.100.1\nC: route add -net 192.168.122.0 netmask 255.255.255.0 gw 192.168.122.1\niptables -A FORWARD -i virbr1 -o virbr0 -j ACCEPT iptables -A FORWARD -i virbr0 -o virbr1 -m state \u0026ndash;state ESTABLISHED,RELATED -j ACCEPT iptables -t nat -A POSTROUTING -o virbr0 -j MASQUERADE\niptables -t nat -vnL POSTROUTING \u0026ndash;line-number iptables -t nat -D POSTROUTING 20 iptables-save route route del -net 192.168.40.0 netmask 255.255.255.0 route del -net 192.168.30.0 netmask 255.255.255.0\nroute del -net 192.169.30.0 netmask 255.255.255.0 dev virbr0 route del -net 192.169.40.0 netmask 255.255.255.0 dev virbr1\nB: echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward wlo1 iptables -t nat -A POSTROUTING -s 192.168.20.0/24 -d 192.168.40.0/24 -o wlo1 -j MASQUERADE iptables -t nat -A POSTROUTING -s 192.168.20.0/24 -d 192.168.40.0/24 -o virbr1 -j MASQUERADE iptables -t nat -A POSTROUTING -s 192.168.30.0/24 -d 192.168.40.0/24 -o virbr1 -j MASQUERADE iptables -t nat -A POSTROUTING -s 192.168.40.0/24 -d 192.168.30.0/24 -o virbr0 -j MASQUERADE\nroute add -net 192.168.40.0 netmask 255.255.255.0 gw 192.168.40.205 route add -net 192.168.30.0 netmask 255.255.255.0 gw 192.168.30.235\nroute add -net 192.169.30.0 netmask 255.255.255.0 dev virbr0 route add -net 192.169.40.0 netmask 255.255.255.0 dev virbr1\nA: route add -net 192.168.40.0 netmask 255.255.255.0 gw 192.168.30.1\nroute del -net 192.168.40.0 netmask 255.255.255.0 route add -net 192.168.40.0 netmask 255.255.0.0 gw 192.168.3.34 dev enp1s0\nC: route add -net 192.168.30.0 netmask 255.255.255.0 gw 192.168.40.1\nroute del -net 192.168.30.0 netmask 255.255.255.0 route add -net 192.168.30.0 netmask 255.255.0.0 gw 192.168.3.34\nLinux一块网卡添加多个IP地址 https://cloud.tencent.com/developer/article/1431717\nhttps://virt-manager.org/\n黄总 sudo ip addr add 10.252.3.88/29 dev ens1f1 sudo route add 88.88.43.8 gw 10.246.1.173\nsudo ip route add 88.88.43.0/24 via 10.246.1.173 sudo iptables -t nat -A PREROUTING -i ens1f1 -d 10.252.3.88 -j DNAT \u0026ndash;to 88.88.43.8 sudo iptables -t nat -I POSTROUTING -d 88.88.43.8 -o ens1f1 -j SNAT \u0026ndash;to-source 10.252.3.88\nsudo iptables -t nat -A POSTROUTING -d 88.88.43.8 -o cni0 -j SNAT \u0026ndash;to-source 10.252.3.88\n源地址 10.23.80.228 转换为 88.88.44.3，添加此地址回程路由 sudo route add 88.88.44.3 gw 10.246.1.173\n查看登录日志 sudo tail /var/log/auth.log\n","date":"2022-08-25T01:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/iptables/","title":"iptables"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  专线两端IP： A：10.246.1.173 B：10.246.1.174 A出口伪IP：88.88.44.3（回程IP） A入口伪IP：88.88.43.8 ANAT内部IP：10.23.80.228-230 B中心服务器伪NAT内部IP：10.252.3.88/29 配置方法： sudo ip addr add 10.252.3.88/29 dev ens1f1 #添加伪NATIP sudo route add 88.88.43.8 gw 10.246.1.173 #出口网关 sudo route add 88.88.44.3 gw 10.246.1.173 #入口网关 sudo iptables -t nat -A PREROUTING -i ens1f1 -d 10.252.3.88 -j DNAT --to 88.88.44.3 sudo iptables -t nat -I POSTROUTING -d 88.88.43.8 -o ens1f1 -j SNAT --to-source 10.252.3.88   ","date":"2022-08-25T01:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/iptables/","title":"iptables"},{"content":"准备镜像文件\n导入\n1  sudo k3s ctr images import pause.tar.gz   查看\n1  crictl images|grep pause   ","date":"2022-08-19T17:36:18+08:00","permalink":"https://mkbooks.github.io/blog/p/k3s%E6%89%8B%E5%8A%A8%E5%AF%BC%E5%85%A5%E9%95%9C%E5%83%8F/","title":"k3s手动导入镜像"},{"content":"参考链接\n https://www.ruanyifeng.com/blog/2020/08/rsync.html How To Use Rsync to Sync Local and Remote Directories on a VPS, Justin Ellingwood Mirror Your Web Site With rsync, Falko Timme Examples on how to use Rsync, Egidio Docile How to create incremental backups using rsync on Linux, Egidio Docile  一、简介 rsync 是一个常用的 Linux 应用程序，用于文件同步。\n它可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件（但不支持两台远程计算机之间的同步）。它也可以当作文件复制工具，替代cp和mv命令。\n它名称里面的r指的是 remote，rsync 其实就是\u0026quot;远程同步\u0026quot;（remote sync）的意思。与其他文件传输工具（如 FTP 或 scp）不同，rsync 的最大特点是会检查发送方和接收方已有的文件，仅传输有变动的部分（默认规则是文件大小或修改时间有变动）。\n二、安装 1 2 3 4 5  # Ubuntu/Debian $ sudo apt-get install rsync # CentOS/Red Hat $ sudo yum install rsync   注意，传输的双方都必须安装 rsync。\n三、基本用法 3.1 -r 参数 本机使用 rsync 命令时，可以作为cp和mv命令的替代方法，将源目录同步到目标目录。\n1  $ rsync -r source destination   上面命令中，-r表示递归，即包含子目录。注意，-r是必须的，否则 rsync 运行不会成功。source目录表示源目录，destination表示目标目录。\n如果有多个文件或目录需要同步，可以写成下面这样。\n1  $ rsync -r source1 source2 destination   上面命令中，source1、source2都会被同步到destination目录。\n3.2 -a 参数 -a参数可以替代-r，除了可以递归同步以外，还可以同步元信息（比如修改时间、权限等）。由于 rsync 默认使用文件大小和修改时间决定文件是否需要更新，所以-a比-r更有用。下面的用法才是常见的写法。\n1  $ rsync -a source destination   目标目录destination如果不存在，rsync 会自动创建。执行上面的命令后，源目录source被完整地复制到了目标目录destination下面，即形成了destination/source的目录结构。\n如果只想同步源目录source里面的内容到目标目录destination，则需要在源目录后面加上斜杠。\n1  $ rsync -a source/ destination   上面命令执行后，source目录里面的内容，就都被复制到了destination目录里面，并不会在destination下面创建一个source子目录。\n3.3 -n 参数 如果不确定 rsync 执行后会产生什么结果，可以先用-n或\u0026ndash;dry-run参数模拟执行的结果。\n1  $ rsync -anv source/ destination   上面命令中，-n参数模拟命令执行的结果，并不真的执行命令。-v参数则是将结果输出到终端，这样就可以看到哪些内容会被同步。\n3.4 \u0026ndash;delete 参数 默认情况下，rsync 只确保源目录的所有内容（明确排除的文件除外）都复制到目标目录。它不会使两个目录保持相同，并且不会删除文件。如果要使得目标目录成为源目录的镜像副本，则必须使用\u0026ndash;delete参数，这将删除只存在于目标目录、不存在于源目录的文件。\n1  $ rsync -av --delete source/ destination   上面命令中，\u0026ndash;delete参数会使得destination成为source的一个镜像。\n四、排除文件 4.1 \u0026ndash;exclude 参数 有时，我们希望同步时排除某些文件或目录，这时可以用\u0026ndash;exclude参数指定排除模式。\n1 2 3  $ rsync -av --exclude=\u0026#39;*.txt\u0026#39; source/ destination # 或者 $ rsync -av --exclude \u0026#39;*.txt\u0026#39; source/ destination   上面命令排除了所有 TXT 文件。\n注意，rsync 会同步以\u0026quot;点\u0026quot;开头的隐藏文件，如果要排除隐藏文件，可以这样写\u0026ndash;exclude=\u0026quot;.*\u0026quot;。\n如果要排除某个目录里面的所有文件，但不希望排除目录本身，可以写成下面这样。\n1  $ rsync -av --exclude \u0026#39;dir1/*\u0026#39; source/ destination   多个排除模式，可以用多个\u0026ndash;exclude参数。\n1  $ rsync -av --exclude \u0026#39;file1.txt\u0026#39; --exclude \u0026#39;dir1/*\u0026#39; source/ destination   多个排除模式也可以利用 Bash 的大扩号的扩展功能，只用一个\u0026ndash;exclude参数。\n1  $ rsync -av --exclude={\u0026#39;file1.txt\u0026#39;,\u0026#39;dir1/*\u0026#39;} source/ destination   如果排除模式很多，可以将它们写入一个文件，每个模式一行，然后用\u0026ndash;exclude-from参数指定这个文件。\n1  $ rsync -av --exclude-from=\u0026#39;exclude-file.txt\u0026#39; source/ destination   4.2 \u0026ndash;include 参数 \u0026ndash;include参数用来指定必须同步的文件模式，往往与\u0026ndash;exclude结合使用。\n1  $ rsync -av --include=\u0026#34;*.txt\u0026#34; --exclude=\u0026#39;*\u0026#39; source/ destination   上面命令指定同步时，排除所有文件，但是会包括 TXT 文件。\n五、远程同步 5.1 SSH 协议 rsync 除了支持本地两个目录之间的同步，也支持远程同步。它可以将本地内容，同步到远程服务器。\n1  $ rsync -av source/ username@remote_host:destination   也可以将远程内容同步到本地。\n1  $ rsync -av username@remote_host:source/ destination   rsync 默认使用 SSH 进行远程登录和数据传输。\n由于早期 rsync 不使用 SSH 协议，需要用-e参数指定协议，后来才改的。所以，下面-e ssh可以省略。\n1  $ rsync -av -e ssh source/ user@remote_host:/destination   但是，如果 ssh 命令有附加的参数，则必须使用-e参数指定所要执行的 SSH 命令。\n1  $ rsync -av -e \u0026#39;ssh -p 2234\u0026#39; source/ user@remote_host:/destination   上面命令中，-e参数指定 SSH 使用2234端口。\n5.2 rsync 协议 除了使用 SSH，如果另一台服务器安装并运行了 rsync 守护程序，则也可以用rsync://协议（默认端口873）进行传输。具体写法是服务器与目标目录之间使用双冒号分隔::。\n1  $ rsync -av source/ 192.168.122.32::module/destination   注意，上面地址中的module并不是实际路径名，而是 rsync 守护程序指定的一个资源名，由管理员分配。\n如果想知道 rsync 守护程序分配的所有 module 列表，可以执行下面命令。\n1  $ rsync rsync://192.168.122.32   rsync 协议除了使用双冒号，也可以直接用rsync://协议指定地址。\n1  $ rsync -av source/ rsync://192.168.122.32/module/destination   六、增量备份 rsync 的最大特点就是它可以完成增量备份，也就是默认只复制有变动的文件。\n除了源目录与目标目录直接比较，rsync 还支持使用基准目录，即将源目录与基准目录之间变动的部分，同步到目标目录。\n具体做法是，第一次同步是全量备份，所有文件在基准目录里面同步一份。以后每一次同步都是增量备份，只同步源目录与基准目录之间有变动的部分，将这部分保存在一个新的目标目录。这个新的目标目录之中，也是包含所有文件，但实际上，只有那些变动过的文件是存在于该目录，其他没有变动的文件都是指向基准目录文件的硬链接。\n\u0026ndash;link-dest参数用来指定同步时的基准目录。\n1  $ rsync -a --delete --link-dest /compare/path /source/path /target/path   上面命令中，\u0026ndash;link-dest参数指定基准目录/compare/path，然后源目录/source/path跟基准目录进行比较，找出变动的文件，将它们拷贝到目标目录/target/path。那些没变动的文件则会生成硬链接。这个命令的第一次备份时是全量备份，后面就都是增量备份了。\n下面是一个脚本示例，备份用户的主目录。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #!/bin/bash  # A script to perform incremental backups using rsync set -o errexit set -o nounset set -o pipefail readonly SOURCE_DIR=\u0026#34;${HOME}\u0026#34; readonly BACKUP_DIR=\u0026#34;/mnt/data/backups\u0026#34; readonly DATETIME=\u0026#34;$(date \u0026#39;+%Y-%m-%d_%H:%M:%S\u0026#39;)\u0026#34; readonly BACKUP_PATH=\u0026#34;${BACKUP_DIR}/${DATETIME}\u0026#34; readonly LATEST_LINK=\u0026#34;${BACKUP_DIR}/latest\u0026#34; mkdir -p \u0026#34;${BACKUP_DIR}\u0026#34; rsync -av --delete \\  \u0026#34;${SOURCE_DIR}/\u0026#34; \\  --link-dest \u0026#34;${LATEST_LINK}\u0026#34; \\  --exclude=\u0026#34;.cache\u0026#34; \\  \u0026#34;${BACKUP_PATH}\u0026#34; rm -rf \u0026#34;${LATEST_LINK}\u0026#34; ln -s \u0026#34;${BACKUP_PATH}\u0026#34; \u0026#34;${LATEST_LINK}\u0026#34;   上面脚本中，每一次同步都会生成一个新目录${BACKUP_DIR}/${DATETIME}，并将软链接${BACKUP_DIR}/latest指向这个目录。下一次备份时，就将${BACKUP_DIR}/latest作为基准目录，生成新的备份目录。最后，再将软链接${BACKUP_DIR}/latest指向新的备份目录。\n七、配置项 -a、\u0026ndash;archive参数表示存档模式，保存所有的元数据，比如修改时间（modification time）、权限、所有者等，并且软链接也会同步过去。\n\u0026ndash;append参数指定文件接着上次中断的地方，继续传输。\n\u0026ndash;append-verify参数跟\u0026ndash;append参数类似，但会对传输完成后的文件进行一次校验。如果校验失败，将重新发送整个文件。\n-b、\u0026ndash;backup参数指定在删除或更新目标目录已经存在的文件时，将该文件更名后进行备份，默认行为是删除。更名规则是添加由\u0026ndash;suffix参数指定的文件后缀名，默认是~。\n\u0026ndash;backup-dir参数指定文件备份时存放的目录，比如\u0026ndash;backup-dir=/path/to/backups。\n\u0026ndash;bwlimit参数指定带宽限制，默认单位是 KB/s，比如\u0026ndash;bwlimit=100。\n-c、\u0026ndash;checksum参数改变rsync的校验方式。默认情况下，rsync 只检查文件的大小和最后修改日期是否发生变化，如果发生变化，就重新传输；使用这个参数以后，则通过判断文件内容的校验和，决定是否重新传输。\n\u0026ndash;delete参数删除只存在于目标目录、不存在于源目标的文件，即保证目标目录是源目标的镜像。\n-e参数指定使用 SSH 协议传输数据。\n\u0026ndash;exclude参数指定排除不进行同步的文件，比如\u0026ndash;exclude=\u0026quot;*.iso\u0026quot;。\n\u0026ndash;exclude-from参数指定一个本地文件，里面是需要排除的文件模式，每个模式一行。\n\u0026ndash;existing、\u0026ndash;ignore-non-existing参数表示不同步目标目录中不存在的文件和目录。\n-h参数表示以人类可读的格式输出。\n-h、\u0026ndash;help参数返回帮助信息。\n-i参数表示输出源目录与目标目录之间文件差异的详细情况。\n\u0026ndash;ignore-existing参数表示只要该文件在目标目录中已经存在，就跳过去，不再同步这些文件。\n\u0026ndash;include参数指定同步时要包括的文件，一般与\u0026ndash;exclude结合使用。\n\u0026ndash;link-dest参数指定增量备份的基准目录。\n-m参数指定不同步空目录。\n\u0026ndash;max-size参数设置传输的最大文件的大小限制，比如不超过200KB（\u0026ndash;max-size=\u0026lsquo;200k\u0026rsquo;）。\n\u0026ndash;min-size参数设置传输的最小文件的大小限制，比如不小于10KB（\u0026ndash;min-size=10k）。\n-n参数或\u0026ndash;dry-run参数模拟将要执行的操作，而并不真的执行。配合-v参数使用，可以看到哪些内容会被同步过去。\n-P参数是\u0026ndash;progress和\u0026ndash;partial这两个参数的结合。\n\u0026ndash;partial参数允许恢复中断的传输。不使用该参数时，rsync会删除传输到一半被打断的文件；使用该参数后，传输到一半的文件也会同步到目标目录，下次同步时再恢复中断的传输。一般需要与\u0026ndash;append或\u0026ndash;append-verify配合使用。\n\u0026ndash;partial-dir参数指定将传输到一半的文件保存到一个临时目录，比如\u0026ndash;partial-dir=.rsync-partial。一般需要与\u0026ndash;append或\u0026ndash;append-verify配合使用。\n\u0026ndash;progress参数表示显示进展。\n-r参数表示递归，即包含子目录。\n\u0026ndash;remove-source-files参数表示传输成功后，删除发送方的文件。\n\u0026ndash;size-only参数表示只同步大小有变化的文件，不考虑文件修改时间的差异。\n\u0026ndash;suffix参数指定文件名备份时，对文件名添加的后缀，默认是~。\n-u、\u0026ndash;update参数表示同步时跳过目标目录中修改时间更新的文件，即不同步这些有更新的时间戳的文件。\n-v参数表示输出细节。-vv表示输出更详细的信息，-vvv表示输出最详细的信息。\n\u0026ndash;version参数返回 rsync 的版本。\n-z参数指定同步时压缩数据。\n","date":"2022-08-19T17:03:18+08:00","permalink":"https://mkbooks.github.io/blog/p/%E8%BF%9C%E7%A8%8B%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6-rsync/","title":"远程传输文件-rsync"},{"content":"转载: https://docs.rancher.cn/docs/rke/upgrades/configuring-strategy/_index/#%E9%A9%B1%E9%80%90%E8%8A%82%E7%82%B9\n驱逐节点 默认情况下，升级节点前需要使用kubectl cordon命令将节点标记为“不可用”，这个标记的目的是防止在节点在升级的过程中因为被分配到新的 pods 或者流量而中断。完成升级后，您需要使用kubectl uncordon命令将节点重新标记为“可用”，此时可以将 pods 和流量分配到该节点上。该操作不会对节点上已有的 pods 造成影响。\n1 2  kubectl cordon node_name kubectl uncordon node_name   除了将节点标记为“不可用”外，您也可以使用kubectl drain命令，在升级节点前将节点内的所有 pod 驱逐到其他节点上，并且将其标记为“不可用”，确保这个节点内在升级完成之前不会有正在运行的 pods。kubectl drain命令会导致节点内所有的 pods 被驱逐。\n1  kubectl drain --ignore-daemonsets node_name   请参考Kubernetes 官方文档，了解驱逐节点的注意事项。\n注意：drain的默认值是false，如果将它的值改为true，会导致 worker 节点在升级之前被驱逐，无法升级 worker 节点。\n1 2 3 4 5 6 7 8 9 10  upgrade_strategy: max_unavailable_worker: 10% max_unavailable_controlplane: 1 drain: false node_drain_input: force: false ignore_daemonsets: true delete_local_data: false grace_period: -1 // grace period specified for each pod spec will be used timeout: 60   ","date":"2022-08-18T10:03:18+08:00","permalink":"https://mkbooks.github.io/blog/p/k8s-%E9%A9%B1%E9%80%90%E8%8A%82%E7%82%B9/","title":"k8s 驱逐节点"},{"content":"1  find . -type f -name \u0026#34;*.yaml\u0026#34; | xargs sed -i \u0026#34;s#host_path#$host_path#g\u0026#34;   ","date":"2022-08-17T17:38:18+08:00","permalink":"https://mkbooks.github.io/blog/p/%E6%9B%BF%E6%8D%A2%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E7%9A%84%E7%89%B9%E5%AE%9A%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"替换文件夹中所有文件内容的特定字符串"},{"content":"转载: https://www.cnblogs.com/fengdejiyixx/p/15186831.html\n注意：以下操作方法十分危险，三思而行！！！\n如果名称空间、pod、pv、pvc全部处于“Terminating”状态时，此时的该名称空间下的所有控制器都已经被删除了，之所以出现pod、pvc、pv、ns无法删除，那是因为kubelet 阻塞，有其他的资源在使用该namespace，比如CRD等，尝试重启kubelet，再删除该namespace 也不好使。\n正确的删除方法：删除pod\u0026ndash;\u0026gt; 删除pvc \u0026mdash;\u0026gt; 删除pv \u0026ndash;\u0026gt; 删除名称空间\n1. 强制删除pod 1  kubectl delete pod \u0026lt;your-pod-name\u0026gt; -n \u0026lt;name-space\u0026gt; --force --grace-period=0   解决方法：加参数 \u0026ndash;force \u0026ndash;grace-period=0，grace-period表示过渡存活期，默认30s，在删除POD之前允许POD慢慢终止其上的容器进程，从而优雅退出，0表示立即终止POD\n2. 强制删除pv、pvc 1 2  kubectl patch pv xxx -p \u0026#39;{\u0026#34;metadata\u0026#34;:{\u0026#34;finalizers\u0026#34;:null}}\u0026#39; kubectl patch pvc xxx -p \u0026#39;{\u0026#34;metadata\u0026#34;:{\u0026#34;finalizers\u0026#34;:null}}\u0026#39;   直接删除 k8s etcd 数据库中的记录！\n3. 强制删除ns 在尝试以下命令强制删除也不好使：\n1  kubectl delete ns \u0026lt;terminating-namespace\u0026gt; --force --grace-period=0   解决方法：\n1）运行以下命令以查看处于“Terminating”状态的namespace：\n1  kubectl get namespaces   2）选择一个Terminating namespace，并查看namespace 中的 finalizer。运行以下命令：\n1  $ kubectl get namespace \u0026lt;terminating-namespace\u0026gt; -o yaml   输出信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  apiVersion: v1 kind: Namespace metadata: creationTimestamp: \u0026#34;2019-11-20T15:18:06Z\u0026#34; deletionTimestamp: \u0026#34;2020-01-16T02:50:02Z\u0026#34; name: \u0026lt;terminating-namespace\u0026gt; resourceVersion: \u0026#34;3249493\u0026#34; selfLink: /api/v1/namespaces/knative-eventing uid: f300ea38-c8c2-4653-b432-b66103e412db spec: finalizers: - kubernetes status:   3）导出json格式到文件\n1  kubectl get namespace \u0026lt;terminating-namespace\u0026gt; -o json \u0026gt;tmp.json   4）编辑tmp.josn，删除finalizers 字段的值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  { \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;Namespace\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2019-11-20T15:18:06Z\u0026#34;, \u0026#34;deletionTimestamp\u0026#34;: \u0026#34;2020-01-16T02:50:02Z\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;\u0026lt;terminating-namespace\u0026gt;\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;3249493\u0026#34;, \u0026#34;selfLink\u0026#34;: \u0026#34;/api/v1/namespaces/knative-eventing\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;f300ea38-c8c2-4653-b432-b66103e412db\u0026#34; }, \u0026#34;spec\u0026#34;: { #从此行开始删除 \u0026#34;finalizers\u0026#34;: [] }, # 删到此行 \u0026#34;status\u0026#34;: { \u0026#34;phase\u0026#34;: \u0026#34;Terminating\u0026#34; } }   5）开启proxy\n1  kubectl proxy   执行该命令后，当前终端会被卡住 6）打开新的一个窗口，执行以下命令\n1  curl -k -H \u0026#34;Content-Type: application/json\u0026#34; -X PUT --data-binary @tmp.json http://127.0.0.1:8001/api/v1/namespaces/\u0026lt;terminating-namespace\u0026gt;/finalize   输出信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  { \u0026#34;kind\u0026#34;: \u0026#34;Namespace\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;istio-system\u0026#34;, \u0026#34;selfLink\u0026#34;: \u0026#34;/api/v1/namespaces/istio-system/finalize\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;2e274537-727f-4a8f-ae8c-397473ed619a\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;3249492\u0026#34;, \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2019-11-20T15:18:06Z\u0026#34;, \u0026#34;deletionTimestamp\u0026#34;: \u0026#34;2020-01-16T02:50:02Z\u0026#34; }, \u0026#34;spec\u0026#34;: { }, \u0026#34;status\u0026#34;: { \u0026#34;phase\u0026#34;: \u0026#34;Terminating\u0026#34; } }   7）确认处于Terminating 状态的namespace已经被删除\n1  kubectl get namespaces   如果还有处于Terminating 状态的namespace，重复以上操作，删除即可！\n","date":"2022-08-17T11:03:18+08:00","permalink":"https://mkbooks.github.io/blog/p/k8s%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4podpvpvc%E5%92%8Cnsnamespace%E6%96%B9%E6%B3%95/","title":"k8s强制删除pod\u0026pv\u0026pvc和ns\u0026namespace方法"},{"content":"转载: https://www.cnblogs.com/zisefeizhu/p/13786053.html\n在k8s集群中进行测试删除namespace是经常的事件，而为了方便操作，一般都是直接对整个名称空间进行删除操作。 相信道友们在进行此步操作的时候，会遇到要删除的namespace一直处于Terminating。下面我将给出一个完美的解决方案，\n测试demo\n1 2 3 4 5 6 7 8 9 10 11 12 13  创建demo namespace # kubectl create ns test namespace/test created 删除demo namespace # kubectl delete ns test namespace \u0026#34;test\u0026#34; deleted 一直处于deleted不见exit 查看状态 可见test namespace 处于Terminating # kubectl get ns -w NAME STATUS AGE test Terminating 18s   下面给出一种完美的解决方案：调用接口删除\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  开启一个代理终端 # kubectl proxy Starting to serve on 127.0.0.1:8001 再开启一个操作终端 将test namespace的配置文件输出保存 # kubectl get ns test -o json \u0026gt; test.json 删除spec及status部分的内容还有metadata字段后的\u0026#34;,\u0026#34;号，切记！ 剩下内容大致如下 { \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;Namespace\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;annotations\u0026#34;: { \u0026#34;cattle.io/status\u0026#34;: \u0026#34;{\\\u0026#34;Conditions\\\u0026#34;:[{\\\u0026#34;Type\\\u0026#34;:\\\u0026#34;ResourceQuotaInit\\\u0026#34;,\\\u0026#34;Status\\\u0026#34;:\\\u0026#34;True\\\u0026#34;,\\\u0026#34;Message\\\u0026#34;:\\\u0026#34;\\\u0026#34;,\\\u0026#34;LastUpdateTime\\\u0026#34;:\\\u0026#34;2020-10-09T07:12:17Z\\\u0026#34;},{\\\u0026#34;Type\\\u0026#34;:\\\u0026#34;InitialRolesPopulated\\\u0026#34;,\\\u0026#34;Status\\\u0026#34;:\\\u0026#34;True\\\u0026#34;,\\\u0026#34;Message\\\u0026#34;:\\\u0026#34;\\\u0026#34;,\\\u0026#34;LastUpdateTime\\\u0026#34;:\\\u0026#34;2020-10-09T07:12:18Z\\\u0026#34;}]}\u0026#34;, \u0026#34;lifecycle.cattle.io/create.namespace-auth\u0026#34;: \u0026#34;true\u0026#34; }, \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2020-10-09T07:12:16Z\u0026#34;, \u0026#34;deletionTimestamp\u0026#34;: \u0026#34;2020-10-09T07:12:22Z\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;471648079\u0026#34;, \u0026#34;selfLink\u0026#34;: \u0026#34;/api/v1/namespaces/test\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;862d311e-d87a-48c2-bc48-332a4db9dbdb\u0026#34; } } 调接口删除 # curl -k -H \u0026#34;Content-Type: application/json\u0026#34; -X PUT --data-binary @test.json http://127.0.0.1:8001/api/v1/namespaces/test/finalize { \u0026#34;kind\u0026#34;: \u0026#34;Namespace\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;selfLink\u0026#34;: \u0026#34;/api/v1/namespaces/test/finalize\u0026#34;, \u0026#34;uid\u0026#34;: \u0026#34;862d311e-d87a-48c2-bc48-332a4db9dbdb\u0026#34;, \u0026#34;resourceVersion\u0026#34;: \u0026#34;471648079\u0026#34;, \u0026#34;creationTimestamp\u0026#34;: \u0026#34;2020-10-09T07:12:16Z\u0026#34;, \u0026#34;deletionTimestamp\u0026#34;: \u0026#34;2020-10-09T07:12:22Z\u0026#34;, \u0026#34;annotations\u0026#34;: { \u0026#34;cattle.io/status\u0026#34;: \u0026#34;{\\\u0026#34;Conditions\\\u0026#34;:[{\\\u0026#34;Type\\\u0026#34;:\\\u0026#34;ResourceQuotaInit\\\u0026#34;,\\\u0026#34;Status\\\u0026#34;:\\\u0026#34;True\\\u0026#34;,\\\u0026#34;Message\\\u0026#34;:\\\u0026#34;\\\u0026#34;,\\\u0026#34;LastUpdateTime\\\u0026#34;:\\\u0026#34;2020-10-09T07:12:17Z\\\u0026#34;},{\\\u0026#34;Type\\\u0026#34;:\\\u0026#34;InitialRolesPopulated\\\u0026#34;,\\\u0026#34;Status\\\u0026#34;:\\\u0026#34;True\\\u0026#34;,\\\u0026#34;Message\\\u0026#34;:\\\u0026#34;\\\u0026#34;,\\\u0026#34;LastUpdateTime\\\u0026#34;:\\\u0026#34;2020-10-09T07:12:18Z\\\u0026#34;}]}\u0026#34;, \u0026#34;lifecycle.cattle.io/create.namespace-auth\u0026#34;: \u0026#34;true\u0026#34; } }, \u0026#34;spec\u0026#34;: { }, \u0026#34;status\u0026#34;: { \u0026#34;phase\u0026#34;: \u0026#34;Terminating\u0026#34;, \u0026#34;conditions\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;NamespaceDeletionDiscoveryFailure\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;True\u0026#34;, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2020-10-09T07:12:27Z\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;DiscoveryFailed\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Discovery failed for some groups, 1 failing: unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: the server is currently unable to handle the request\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;NamespaceDeletionGroupVersionParsingFailure\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;False\u0026#34;, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2020-10-09T07:12:28Z\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;ParsedGroupVersions\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;All legacy kube types successfully parsed\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;NamespaceDeletionContentFailure\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;False\u0026#34;, \u0026#34;lastTransitionTime\u0026#34;: \u0026#34;2020-10-09T07:12:28Z\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;ContentDeleted\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;All content successfully deleted\u0026#34; } ] } }   查看结果\n1 2 3 4 5 6 7 8  1、delete 状态终止 kubectl delete ns test namespace \u0026#34;test\u0026#34; deleted 2、Terminating状态终止 kubectl get ns -w test Terminating 18s test Terminating 17m   名称空间被删除掉\n","date":"2022-08-17T11:03:18+08:00","permalink":"https://mkbooks.github.io/blog/p/k8s%E7%9A%84namespace%E4%B8%80%E7%9B%B4terminating%E7%9A%84%E5%AE%8C%E7%BE%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","title":"k8s的namespace一直Terminating的完美解决方案"},{"content":"参考: https://blog.csdn.net/laobai1015/article/details/98628860\n需求  把 /etc/rancher/k3s/k3s.yaml 文件的内容，每行前面加 4 个空格，追加到 ai-service-platform/yamls/config/kube-config.yaml 文件中； 把 ai-service-platform/yamls/config/kube-config.yaml 文件中的 127.0.0.1 替换成 $master_host_ip。  脚本：\n1 2 3 4  function fix_kube_config(){ sudo awk \u0026#39;{print \u0026#34; \u0026#34; $0 \u0026gt;\u0026gt; \u0026#34;ai-service-platform/yamls/config/kube-config.yaml\u0026#34;}\u0026#39; /etc/rancher/k3s/k3s.yaml sed -i \u0026#34;s/127.0.0.1/$master_host_ip/g\u0026#34; ai-service-platform/yamls/config/kube-config.yaml }   扩展 在前面、后面、指定列添加相同字符\n 给一个文件中的每一行开头插入字符的方法：awk \u0026lsquo;{print \u0026ldquo;需要添加的字符\u0026rdquo; $0}\u0026rsquo; fileName 给一个文件中的每一行结尾插入字符的方法：awk \u0026lsquo;{print $0 \u0026ldquo;需要添加的字符\u0026rdquo;}\u0026rsquo; fileName 给一个文件中的每一行的指定列插入字符的方法：awk \u0026lsquo;$0=$0 X\u0026quot;\u0026rsquo; fileName  删除某一个列\n 删除文件中的第一列：awk \u0026lsquo;{$1=\u0026quot;\u0026quot;;print $0}\u0026rsquo; fileName 或者另一种方法 sed -e \u0026rsquo;s/[^ ]* //' text 删除指定列：awk \u0026lsquo;{$Num=\u0026quot;\u0026quot;;print $0}\u0026rsquo; fileName  把Num换成要删除的列数即可\n练习 给文件中的每一行开头添加drop tables\n1  awk \u0026#39;{print \u0026#34;drop table \u0026#34;$0}\u0026#39; aa.txt \u0026gt; bb.txt   给文件中的每一行结尾添加分号\n1  awk \u0026#39;{print $0\u0026#34;;\u0026#34;}\u0026#39; bb.txt \u0026gt; cc.txt   ","date":"2022-08-17T10:03:18+08:00","permalink":"https://mkbooks.github.io/blog/p/linux-%E4%B8%8B%E4%BD%BF%E7%94%A8-awk-%E6%93%8D%E4%BD%9C%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9/","title":"Linux 下使用 awk 操作文件内容"},{"content":"参考: https://developer.aliyun.com/article/53579\nmycode\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import os import math if __name__ == \u0026#39;__main__\u0026#39;: vfs = os.statvfs(\u0026#34;/home/manager\u0026#34;) g = 1024 * 1024 * 1024 # 总容量 k_blocks = vfs.f_bsize * vfs.f_blocks / g # Used,使用量，总容量减去空闲容量 used = vfs.f_bsize * (vfs.f_blocks - vfs.f_bfree) / g # Available，有效容量 available = vfs.f_bsize * vfs.f_bavail / g # use%,使用量，%,round(浮点数，精确到小数点后的位数） use = round(used / (used + available) * 100, 2) print({ \u0026#34;容量\u0026#34;: k_blocks, \u0026#34;已用\u0026#34;: used, \u0026#34;可用\u0026#34;: available, \u0026#34;已用%\u0026#34;: use, }) print({ \u0026#34;容量\u0026#34;: f\u0026#39;{math.ceil(k_blocks)}G\u0026#39;, \u0026#34;已用\u0026#34;: f\u0026#39;{math.ceil(used)}G\u0026#39;, \u0026#34;可用\u0026#34;: f\u0026#39;{math.ceil(available)}G\u0026#39;, \u0026#34;已用%\u0026#34;: f\u0026#39;{math.ceil(use)}%\u0026#39;, })   运行测试\n1 2 3  $ df -h /home/manager 文件系统 容量 已用 可用 已用% 挂载点 /dev/nvme0n1p2 457G 325G 110G 75% /   1 2 3  python test.py {\u0026#39;容量\u0026#39;: 456.8854446411133, \u0026#39;已用\u0026#39;: 324.40053939819336, \u0026#39;可用\u0026#39;: 109.20629501342773, \u0026#39;已用%\u0026#39;: 74.81} {\u0026#39;容量\u0026#39;: \u0026#39;457G\u0026#39;, \u0026#39;已用\u0026#39;: \u0026#39;325G\u0026#39;, \u0026#39;可用\u0026#39;: \u0026#39;110G\u0026#39;, \u0026#39;已用%\u0026#39;: \u0026#39;75%\u0026#39;}   ","date":"2022-08-15T17:03:18+08:00","permalink":"https://mkbooks.github.io/blog/p/python-%E5%AE%9E%E7%8E%B0-linux-%E7%9A%84-df-h-%E5%91%BD%E4%BB%A4/","title":"Python 实现 Linux 的 'df -h' 命令"},{"content":"编辑文件：\n1  sudo gedit /etc/systemd/logind.conf   1 2 3 4  #HandlePowerKey按下电源键后的行为，默认power off #HandleSleepKey 按下挂起键后的行为，默认suspend #HandleHibernateKey按下休眠键后的行为，默认hibernate #HandleLidSwitch合上笔记本盖后的行为，一般为默认suspend（改为ignore；即合盖不休眠）在原文件中，还要去掉前面的#   1 2 3 4  然后将其中的： #HandleLidSwitch=suspend 复制一行到下面，去掉“#”号： HandleLidSwitch=ignore   最后重启服务\n1  service systemd-logind restart   ","date":"2022-08-13T15:33:18+08:00","permalink":"https://mkbooks.github.io/blog/p/ubuntu-%E8%AE%BE%E7%BD%AE%E5%90%88%E4%B8%8A%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%9B%96%E5%AD%90%E4%B8%8D%E4%BC%91%E7%9C%A0%E7%9A%84%E6%96%B9%E6%B3%95/","title":"Ubuntu 设置合上笔记本盖子不休眠的方法"},{"content":"pip freeze \u0026gt; test.txt\npip uninstall -r test.txt -y\npip install -r requirements.txt\n","date":"2022-08-08T18:13:18+08:00","permalink":"https://mkbooks.github.io/blog/p/python-%E6%B8%85%E7%90%86%E5%8C%85/","title":"python 清理包"},{"content":"准备检查：内存条，硬盘，主板电池\n","date":"2022-08-08T18:13:18+08:00","permalink":"https://mkbooks.github.io/blog/p/%E7%94%B5%E8%84%91%E5%BC%80%E4%B8%8D%E4%BA%86%E6%9C%BA/","title":"电脑开不了机"},{"content":"","date":"2022-08-07T15:47:18+08:00","image":"http://changxiangyu.cn/images/small-15x15相册/1.jpg","permalink":"https://mkbooks.github.io/blog/p/%E5%A9%9A%E7%BA%B1%E7%85%A7-15x15-%E7%9B%B8%E5%86%8C/","title":"婚纱照 15x15 相册"},{"content":"","date":"2022-08-07T15:33:18+08:00","image":"https://changxiangyu.cn/images/small/30.jpg","permalink":"https://mkbooks.github.io/blog/p/%E5%A9%9A%E7%BA%B1%E7%85%A7-12x12-%E7%9B%B8%E5%86%8C/","title":"婚纱照 12x12 相册"},{"content":"初见三摆台 至美三件套艺术组合 10X8英寸时尚绢丝相架一幅 10X8英寸精美思慕相架一幅 30X20英寸时尚绢丝挂画一幅 48X24至美相框一幅 6X8英寸时尚蓝色恋人相架一幅 8X12英寸精美米娜相架一幅 8X8英寸安琪相架一幅 ","date":"2022-08-07T15:33:18+08:00","image":"https://changxiangyu.cn/images/small/115.jpg","permalink":"https://mkbooks.github.io/blog/p/%E5%A9%9A%E7%BA%B1%E7%85%A7%E6%91%86%E4%BB%B6/","title":"婚纱照摆件"},{"content":"1 2 3 4 5 6 7 8 9 10 11 12  # 准备工作：安装 imagemagick sudo apt-get install imagemagick #大图所在的目录 cd /path/to/big/images #创建小图对应的目录结构 find . -type d -print -exec mkdir \u0026#39;../small/{}\u0026#39; -p \\; #批量转换! 等比例缩小到320x320之内 320x: 只设置宽度 find . -type f -name \u0026#39;*.jpg\u0026#39; -print -exec \\ convert \u0026#39;{}\u0026#39; -resize 320x320 \u0026#39;../small/{}\u0026#39; \\;   ","date":"2022-08-07T02:33:18+08:00","permalink":"https://mkbooks.github.io/blog/p/ubuntu%E4%B8%8B%E5%9C%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%89%B9%E9%87%8F%E7%94%9F%E6%88%90%E7%BC%A9%E7%95%A5%E5%9B%BE/","title":"Ubuntu下在命令行批量生成缩略图"},{"content":"Step 1: Install Hugo 1 2 3  # Ubuntu 系统 sudo apt update sudo apt install hugo   验证您的新安装:\n1  hugo version   1 2  Output hugo v0.101.0-9f74196ce611cdf6d355bfb99fd8eba5c68ef7f8+extended linux/amd64 BuildDate=2022-06-28T10:02:18Z VendorInfo=snap   Step 2: Create a New Site 1  hugo new site quickstart   这个命令会创建一个名为 quickstart 的目录，这就是博客的根目录。目录结构如下：\n1 2 3 4 5 6 7 8  ├── archetypes │ └── default.md ├── config.toml # 博客站点的配置文件 ├── content # 博客文章所在目录 ├── data ├── layouts # 网站布局 ├── static # 一些静态内容 └── themes # 博客主题   Step 3: Add a Theme 首先，从 GitHub 下载主题并将其添加到站点的主题目录中：\n1 2 3  cd quickstart git init git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke   然后，将主题添加到站点配置中：\n1  echo theme = \\\u0026#34;ananke\\\u0026#34; \u0026gt;\u0026gt; config.toml   Step 4: Add Some Content 1  hugo new posts/my-first-post.md   如果需要，可以编辑新创建的内容文件，它将以如下内容开头：\n1 2 3 4 5  --- title: \u0026#34;My First Post\u0026#34; date: 2019-03-26T08:47:11+01:00 draft: true ---   Step 5: Start the Hugo server 现在，启动启用草稿的 Hugo 服务器：\n1 2 3 4 5 6  hugo server -D # 可以在其它机器访问 hugo server --bind=\u0026#34;0.0.0.0\u0026#34; -D # 可以在其它机器访问, -p 修改端口 hugo server --bind=\u0026#34;0.0.0.0\u0026#34; -p 80 -D   在 http://114.132.247.115:1313/ 导航到您的新站点。\n第 6 步：自定义主题 在文本编辑器中打开 config.toml：\n1 2 3 4  baseURL = \u0026#34;https://example.org/\u0026#34; languageCode = \u0026#34;en-us\u0026#34; title = \u0026#34;My New Hugo Site\u0026#34; theme = \u0026#34;ananke\u0026#34;   第 7 步：构建静态页面 1  hugo -D   ","date":"2022-08-01T19:52:18+08:00","permalink":"https://mkbooks.github.io/blog/p/quick-start/","title":"Quick Start"},{"content":"下载博客主题 创建好博客项目后，接下来是下载hugo博客的主题，这里有很多主题，我们可以任意挑选，比如我们选择了bootstrap4-blog 主题。\n然后在 Blog 目录下使用git 命令来下载主题：\n1  git clone https://github.com/alanorth/hugo-theme-bootstrap4-blog.git themes/hugo-theme-bootstrap4-blog   下载下来的主题会放在themes 目录中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  └── hugo-theme-bootstrap4-blog ├── CHANGELOG.md ├── LICENSE.txt ├── README.md ├── archetypes ├── assets ├── exampleSite # 本主题示例内容 | ├── content # 示例博客文章 │ |-- static │ |-- config.toml # 本主题配置 ├── i18n ├── images ├── layouts ├── package-lock.json ├── package.json ├── screenshot.png ├── source ├── theme.toml └── webpack.config.js   使用主题 1 2 3  vim config.toml theme = \u0026#34;hugo-theme-bootstrap4-blog\u0026#34;   ","date":"2022-08-01T00:00:00Z","permalink":"https://mkbooks.github.io/blog/p/%E4%BF%AE%E6%94%B9%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98/","title":"修改博客主题"},{"content":"准备要部署的内容 在github 上创建一个仓库: chenjinxin.github.io\n要向仓库中存放的内容，使用 hugo 命令生成的。在当前目录下，运行 hugo 命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  ➜ quickstart git:(master) ✗ pwd /home/cjx/quickstart ➜ quickstart git:(master) hugo Start building sites … hugo v0.101.0-9f74196ce611cdf6d355bfb99fd8eba5c68ef7f8+extended linux/amd64 BuildDate=2022-06-28T10:02:18Z VendorInfo=snap | EN -------------------+----- Pages | 28 Paginator pages | 0 Non-page files | 0 Static files | 0 Processed images | 0 Aliases | 12 Sitemaps | 1 Cleaned | 0 Total in 33 ms   执行成功后，会生成一个public 目录，这个目录中的内容，就是我们博客系统的所有内容，我们需要将这些内容存放在Git 仓库中。\n部署到 GitHub 按照如下步骤将博客内容上传到Git 仓库，在public 目录下，依次执行下面的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # 初始化仓库 git init # 将所有内容添加到git git add . # 提交到git 本地 git commit -m \u0026#34;我的博客第一次提交\u0026#34; # 关联到远程git，注意这里需要写你自己的git 地址 git remote add origin git@github.com:chenjinxin1124/chenjinxin.github.io.git # 推送到远程git git push --set-upstream origin master   ","date":"2022-08-01T00:00:00Z","permalink":"https://mkbooks.github.io/blog/p/%E5%B0%86%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E5%9C%A8github%E4%B8%8A/","title":"将博客部署在GitHub上"},{"content":"初始化本地仓库 1  git init   添加代码 1  git add .   提交代码 1  git commit -m\u0026#39;first commit\u0026#39;   添加远程仓库地址 1  git remote add origin git@github.com:jinyumantangcjx/hugo.git   把本地仓库的变化连接到远程仓库主分支 1  git push --set-upstream origin master   ","date":"2022-08-01T00:00:00Z","permalink":"https://mkbooks.github.io/blog/p/%E6%8E%A8%E9%80%81%E5%88%B0github/","title":"推送到GitHub"},{"content":"openvpn 操作系统: Ubuntu 20.04\n参考文档：\nopenVPN官方文档\nDigitalOcean官方文档\n初始服务器设置 OpenVPN 服务器 创建新用户 1 2 3 4 5 6 7  sudo adduser sammy # 授予 sudo 权限 sudo usermod -aG sudo sammy # 切换用户 su sammy   创建密钥对 1 2 3 4  ssh-keygen # 将公钥复制到本机 touch ~/.ssh/authorized_keys \u0026amp;\u0026amp; cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys   CA 服务器 创建新用户 1 2 3 4 5 6 7  sudo adduser sammy # 授予 sudo 权限 sudo usermod -aG sudo sammy # 切换用户 su sammy   创建密钥对 1 2 3 4 5 6 7 8 9 10 11 12  ssh-keygen # 将公钥复制到本机 touch ~/.ssh/authorized_keys \u0026amp;\u0026amp; cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys # 将公钥复制到 OpenVPN 服务器 cat ~/.ssh/id_rsa.pub # 将上面命令执行结果复制到 OpenVPN 服务器的 /home/sammy/.ssh/authorized_keys 文件中 # 将 OpenVPN 服务器的公钥复制到本机，在 OpenVPN 服务器执行下面命令: cat ~/.ssh/id_rsa.pub # 将上面命令执行结果复制到 CA 服务器的 /home/sammy/.ssh/authorized_keys 文件中   安装 Easy-RSA  版本：3.0.6。\n 1 2 3 4 5 6  sudo apt update sudo apt install easy-rsa # 查看版本： dpkg -l|grep easy-rsa ii easy-rsa 3.0.6-1 all Simple shell based CA utility   创建公开密码匙基础建设目录 1 2 3 4 5 6 7  mkdir ~/easy-rsa # 使用此目录创建指向前一步中安装的 easy-rsa 包文件的符号链接。 ln -s /usr/share/easy-rsa/* ~/easy-rsa/ # 确保只有所有者可以使用 chmod 命令访问它: chmod 700 /home/sammy/easy-rsa   在 easy-rsa 目录中初始化 PKI:\n1 2  cd ~/easy-rsa ./easyrsa init-pki   创建证书颁发机构 创建并用一些默认值填充一个名为 vars 的文件。\n1 2 3 4 5 6 7 8 9 10 11  vi vars cat vars set_var EASYRSA_REQ_COUNTRY \u0026#34;CN\u0026#34; set_var EASYRSA_REQ_PROVINCE \u0026#34;GuangDong\u0026#34; set_var EASYRSA_REQ_CITY \u0026#34;ShenZhen\u0026#34; set_var EASYRSA_REQ_ORG \u0026#34;KLB\u0026#34; set_var EASYRSA_REQ_EMAIL \u0026#34;chenjinxin@chenjinxin.cn\u0026#34; set_var EASYRSA_REQ_OU \u0026#34;Community\u0026#34; set_var EASYRSA_ALGO \u0026#34;ec\u0026#34; set_var EASYRSA_DIGEST \u0026#34;sha512\u0026#34;   为证书颁发机构创建根公钥和私钥对(不想每次与 CA 交互时都被提示输入密码，可以使用 nopass 选项运行 build-CA 命令)\n1 2  # 按 ENTER 接受默认配置 ./easyrsa build-ca nopass   安装 OpenVPN 和 Easy-RSA OpenVPN 服务器 更新 OpenVPN 服务器的软件包索引并安装 OpenVPN 和 Easy-RSA。\n1 2 3 4 5 6 7 8 9 10  sudo apt update sudo apt install openvpn easy-rsa # 查看版本 dpkg -l|grep easy-rsa ii easy-rsa 3.0.6-1 all Simple shell based CA utility openvpn --version OpenVPN 2.5.5 x86_64-pc-linux-gnu [SSL (OpenSSL)] [LZO] [LZ4] [EPOLL] [PKCS11] [MH/PKTINFO] [AEAD] built on Mar 22 2022 library versions: OpenSSL 3.0.2 15 Mar 2022, LZO 2.10 ......   在 OpenVPN 服务器上创建一个新目录 ~/easy-rsa, 从 easyrsa 包安装到 ~/easy-rsa 目录中的脚本创建一个符号链接:\n1 2 3 4 5 6  mkdir ~/easy-rsa ln -s /usr/share/easy-rsa/* ~/easy-rsa/ # 确保目录的所有者是您的非 root sudo 用户，并使用chmod以下命令限制对该用户的访问： sudo chown sammy ~/easy-rsa chmod 700 ~/easy-rsa   为 OpenVPN 创建 PKI OpenVPN 服务器 在创建 OpenVPN 服务器的私钥和证书之前，您需要在 OpenVPN 服务器上创建一个本地公钥基础设施目录。您将使用此目录来管理服务器和客户端的证书请求，而不是直接在您的 CA 服务器上进行。\n要在您的 OpenVPN 服务器上构建 PKI 目录，您需要填充一个 vars 使用一些默认值调用的文件。首先您将 cd 进入该 easy-rsa 目录，然后您将使用 vi 或您喜欢的文本编辑器创建和编辑文件。\n1 2  cd ~/easy-rsa vi vars   打开文件后，粘贴以下两行：\n1 2  set_var EASYRSA_ALGO \u0026#34;ec\u0026#34; set_var EASYRSA_DIGEST \u0026#34;sha512\u0026#34;   填充 vars 文件后，您可以继续创建 PKI 目录。为此，请 easyrsa 使用该 init-pki 选项运行脚本。\n1  ./easyrsa init-pki   创建 OpenVPN 服务器证书请求和私钥 OpenVPN 服务器 生成私钥和证书签名请求\n1  cd ~/easy-rsa   现在，您将 easyrsa 使用该 gen-req 选项后跟机器的通用名称 (CN) 来调用。CN 可以是您喜欢的任何内容，但使其具有描述性会很有帮助。在本教程中，OpenVPN 服务器的 CN 将是server. 一定要包括该nopass选项。如果不这样做，将对请求文件进行密码保护，这可能会导致以后出现权限问题。\n注意：如果您选择server此处以外的名称，则必须调整下面的一些说明。例如，将生成的文件复制到/etc/openvpn目录时，您必须替换正确的名称。您还必须/etc/openvpn/server.conf稍后修改该文件以指向正确的.crt和.key文件。\n1  ./easyrsa gen-req server nopass   1 2 3 4 5 6  Output Common Name (eg: your user, host, or server name) [server]: Keypair and certificate request completed. Your files are: req: /home/sammy/easy-rsa/pki/reqs/server.req key: /home/sammy/easy-rsa/pki/private/server.key   这将为服务器创建一个私钥和一个名为server.req. 将服务器密钥复制到/etc/openvpn/server目录：\n1  sudo cp /home/sammy/easy-rsa/pki/private/server.key /etc/openvpn/server/   签署 OpenVPN 服务器的证书请求 CA 服务器 在 OpenVPN 服务器上，作为您的非 root 用户，使用 SCP 或其他传输方法将 server.req 证书请求复制到 CA 服务器进行签名：\n1 2  # scp sammy@your_openvpn_server_ip:/home/sammy/easy-rsa/pki/reqs/server.req /tmp scp sammy@123.125.32.26:/home/sammy/easy-rsa/pki/reqs/server.req /tmp   进入 ~/easy-rsa 创建 PK 的目录，然后使用easyrsa脚本导入证书请求：\n1 2  cd ~/easy-rsa ./easyrsa import-req /tmp/server.req server   1 2 3 4  Output ... The request has been successfully imported with a short name of: server You may now use this name to perform signing operations on this request.   接下来，通过运行easyrsa带有sign-req选项的脚本来签署请求，后跟请求类型和通用名称。请求类型可以是client或server。由于我们正在处理 OpenVPN 服务器的证书请求，请务必使用server请求类型：\n1  ./easyrsa sign-req server server   在输出中，系统会提示您验证请求是否来自受信任的来源。输入yes然后按ENTER确认：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  Output Note: using Easy-RSA configuration from: ./vars Using SSL: openssl OpenSSL 1.1.1f 31 Mar 2020 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a server certificate for 1080 days: subject= commonName = server Type the word \u0026#39;yes\u0026#39; to continue, or any other input to abort. Confirm request details: yes Using configuration from /home/sammy/easy-rsa/pki/safessl-easyrsa.cnf Check that the request matches the signature Signature ok The Subject\u0026#39;s Distinguished Name is as follows commonName :ASN.1 12:\u0026#39;server\u0026#39; Certificate is to be certified until Jul 6 05:46:50 2025 GMT (1080 days) Write out database with 1 new entries Data Base Updated Certificate created at: /home/sammy/easy-rsa/pki/issued/server.crt   完成这些步骤后，您已经使用 CA 服务器的私钥签署了 OpenVPN 服务器的证书请求。生成的server.crt文件包含 OpenVPN 服务器的公共加密密钥，以及来自 CA 服务器的签名。签名的目的是告诉任何信任 CA 服务器的人，当他们连接到 OpenVPN 服务器时，他们也可以信任它。\n要完成配置证书，请将server.crt和ca.crt文件从 CA 服务器复制到 OpenVPN 服务器：\n1 2 3 4  # scp pki/issued/server.crt sammy@your_vpn_server_ip:/tmp # scp pki/ca.crt sammy@your_vpn_server_ip:/tmp scp pki/issued/server.crt sammy@123.125.32.26:/tmp scp pki/ca.crt sammy@123.125.32.26:/tmp   OpenVPN 服务器 现在回到您的 OpenVPN 服务器，将文件复制 /tmp 到 /etc/openvpn/server：\n1  sudo cp /tmp/{server.crt,ca.crt} /etc/openvpn/server   配置 OpenVPN 加密材料 OpenVPN 服务器 为了增加一层安全性，我们将添加一个额外的共享密钥，服务器和所有客户端将使用OpenVPN 的tls-crypt指令。此选项用于混淆服务器和客户端最初相互连接时使用的 TLS 证书。OpenVPN 服务器也使用它来对传入的数据包执行快速检查：如果使用预共享密钥对数据包进行签名，则服务器会对其进行处理；如果它没有签名，那么服务器知道它来自不受信任的来源并且可以丢弃它而不必执行额外的解密工作。\n此选项将有助于确保您的 OpenVPN 服务器能够应对未经身份验证的流量、端口扫描和拒绝服务攻击，这些攻击会占用服务器资源。这也使得识别 OpenVPN 网络流量变得更加困难。\n要生成tls-crypt预共享密钥，请在 OpenVPN 服务器上的~/easy-rsa目录中运行以下命令：\n1 2  cd ~/easy-rsa openvpn --genkey secret ta.key   结果将是一个名为ta.key. 复制到/etc/openvpn/server/目录：\n1  sudo cp ta.key /etc/openvpn/server   将这些文件放在 OpenVPN 服务器上后，您就可以为您的用户创建客户端证书和密钥文件，您将使用它们连接到 VPN。\n生成客户端证书和密钥对 OpenVPN 服务器 尽管您可以在客户端计算机上生成私钥和证书请求，然后将其发送到 CA 进行签名，但本指南概述了在 OpenVPN 服务器上生成证书请求的过程。这种方法的好处是我们可以创建一个脚本，该脚本将自动生成包含所有必需密钥和证书的客户端配置文件。这让您不必将密钥、证书和配置文件传输到客户端，并简化加入 VPN 的过程。\n我们将为本指南生成单个客户端密钥和证书对。如果您有多个客户，您可以对每个客户重复此过程。但请注意，您需要为每个客户端的脚本传递一个唯一的名称值。在本教程中，第一个证书/密钥对称为 client1.\n首先在您的主目录中创建一个目录结构来存储客户端证书和密钥文件：\n1  mkdir -p ~/client-configs/keys   由于您将客户的证书/密钥对和配置文件存储在此目录中，因此您现在应该锁定其权限作为安全措施：\n1  chmod -R 700 ~/client-configs   接下来，导航回 EasyRSA 目录并 easyrsa 使用gen-req 和nopass 选项以及客户端的通用名称运行脚本：\n1 2  cd ~/easy-rsa ./easyrsa gen-req client1 nopass   按 ENTER 确认常用名称。然后，将 client1.key 文件复制到 ~/client-configs/keys/ 您之前创建的目录中：\n1  cp pki/private/client1.key ~/client-configs/keys/   CA 服务器 现在登录到您的 CA 服务器。\n接下来，将 client1.req 使用安全方法将文件传输到您的 CA 服务器：\n1 2  # scp sammy@your_openvpn_server_ip:/home/sammy/easy-rsa/pki/reqs/client1.req /tmp scp sammy@123.125.32.26:/home/sammy/easy-rsa/pki/reqs/client1.req /tmp   然后，导航到 EasyRSA 目录，并导入证书请求：\n1 2  cd ~/easy-rsa ./easyrsa import-req /tmp/client1.req client1   接下来，以与您在上一步中为服务器所做的相同的方式签署请求。不过这一次，请务必指定client请求类型：\n1  ./easyrsa sign-req client client1   出现提示时，输入yes以确认您打算签署证书请求并且它来自受信任的来源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  Output Note: using Easy-RSA configuration from: ./vars Using SSL: openssl OpenSSL 1.1.1f 31 Mar 2020 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a client certificate for 1080 days: subject= commonName = client1 Type the word \u0026#39;yes\u0026#39; to continue, or any other input to abort. Confirm request details: yes Using configuration from /home/sammy/easy-rsa/pki/safessl-easyrsa.cnf Check that the request matches the signature Signature ok The Subject\u0026#39;s Distinguished Name is as follows commonName :ASN.1 12:\u0026#39;client1\u0026#39; Certificate is to be certified until Jul 6 06:18:09 2025 GMT (1080 days) Write out database with 1 new entries Data Base Updated Certificate created at: /home/sammy/easy-rsa/pki/issued/client1.crt   这将创建一个名为client1.crt. 将此文件传输回服务器：\n1 2  # scp pki/issued/client1.crt sammy@your_server_ip:/tmp scp pki/issued/client1.crt sammy@123.125.32.26:/tmp   OpenVPN 服务器 回到您的 OpenVPN 服务器，将客户端证书复制到~/client-configs/keys/目录：\n1  cp /tmp/client1.crt ~/client-configs/keys/   接下来，将 ca.crt 和 ta.key 文件也复制到 ~/client-configs/keys/ 目录中，并为您的 sudo 用户设置适当的权限：\n1 2 3  cp ~/easy-rsa/ta.key ~/client-configs/keys/ sudo cp /etc/openvpn/server/ca.crt ~/client-configs/keys/ sudo chown sammy.sammy ~/client-configs/keys/*   这样，您的服务器和客户端的证书和密钥都已生成并存储在 OpenVPN 服务器上的相应目录中。仍然需要对这些文件执行一些操作，但这些将在稍后的步骤中进行。现在，您可以继续配置 OpenVPN。\n配置 OpenVPN OpenVPN 服务器 像许多其他广泛使用的开源工具一样，OpenVPN 有许多配置选项可用于根据您的特定需求自定义您的服务器。在本节中，我们将提供有关如何根据此软件文档中包含的示例配置文件之一设置 OpenVPN 服务器配置的说明。\n首先，复制示例 server.conf 文件作为您自己的配置文件的起点：\n1  sudo cp /usr/share/doc/openvpn/examples/sample-config-files/server.conf /etc/openvpn/server/   使用您选择的文本编辑器打开新文件进行编辑。我们将在示例中使用 vi：\n1  sudo vi /etc/openvpn/server/server.conf   我们需要更改此文件中的几行。首先，HMAC通过搜索 tls-auth 指令找到配置的部分。默认情况下将启用此行。通过;在行的开头添加 a来注释掉它。然后在它只包含值之后添加一个新行 tls-crypt ta.key：\n/etc/openvpn/server/server.conf\n1 2  ;tls-auth ta.key 0 # This file is secret tls-crypt ta.key   接下来，通过查找cipher行找到有关加密密码的部分。默认值设置为AES-256-CBC，但是，AES-256-GCM密码提供更好的加密级别和性能，并且在最新的 OpenVPN 客户端中得到很好的支持。我们将通过;在此行的开头添加一个符号来注释掉默认值，然后我们将在它包含更新后的值之后添加另一行AES-256-GCM：\n/etc/openvpn/server/server.conf\n1 2  ;cipher AES-256-CBC cipher AES-256-GCM   在此行之后，添加一个auth指令来选择 HMAC 消息摘要算法。为此，SHA256是一个不错的选择：\n/etc/openvpn/server/server.conf\n1  auth SHA256   接下来，找到包含dh指令的行，该指令定义了 Diffie-Hellman 参数。由于我们已将所有证书配置为使用椭圆曲线密码术，因此不需要 Diffie-Hellman 种子文件。注释掉看起来像dh dh2048.pem或的现有行dh dh.pem。Diffie-Hellman 密钥的文件名可能与示例服务器配置文件中列出的不同。然后在它后面添加一行内容dh none：\n/etc/openvpn/server/server.conf\n1 2  ;dh dh2048.pem dh none   接下来，我们希望 OpenVPN 一旦启动就在没有特权的情况下运行，因此我们需要告诉它以用户nobody和组nogroup 运行。要启用此功能，请通过删除每行开头的符号来查找和取消注释user nobody和行：group nogroup;\n/etc/openvpn/server/server.conf\n1 2  user nobody group nogroup   调整 OpenVPN 服务器网络配置 OpenVPN 服务器 服务器网络配置的某些方面需要进行调整，以便 OpenVPN 可以通过 VPN 正确路由流量。其中第一个是IP 转发，这是一种确定 IP 流量应路由到何处的方法。这对于您的服务器将提供的 VPN 功能至关重要。\n要调整 OpenVPN 服务器的默认 IP 转发设置，请 /etc/sysctl.conf 使用 vi 或首选编辑器打开文件：\n1  sudo vi /etc/sysctl.conf   然后在文件底部添加以下行：\n/etc/sysctl.conf\n1  net.ipv4.ip_forward = 1   完成后保存并关闭文件。\n要读取文件并加载当前会话的新值，请键入：\n1  sudo sysctl -p   1 2  Output net.ipv4.ip_forward = 1   现在，您的 OpenVPN 服务器将能够将传入流量从一个以太网设备转发到另一个。此设置确保服务器可以将连接到虚拟 VPN 接口的客户端的流量通过其其他物理以太网设备引导出去。此配置将通过服务器的 IP 地址路由来自客户端的所有网络流量，并且将有效地隐藏客户端的公共 IP 地址。\n在下一步中，您需要配置一些防火墙规则，以确保进出 OpenVPN 服务器的流量正常流动。\n防火墙配置(未开启防火墙可以跳过) OpenVPN 服务器 到目前为止，您已经在服务器上安装了 OpenVPN，对其进行了配置，并生成了客户端访问 VPN 所需的密钥和证书。但是，您尚未向 OpenVPN 提供有关从客户端发送传入 Web 流量的位置的任何说明。您可以通过建立一些防火墙规则和路由配置来规定服务器应如何处理客户端流量。\n假设您遵循了本教程开始时的先决条件，您应该已经ufw在服务器上安装并运行。要允许 OpenVPN 通过防火墙，您需要启用伪装，这是一种 iptables 概念，可提供即时动态网络地址转换 (NAT) 以正确路由客户端连接。\n在打开防火墙配置文件添加伪装规则之前，首先要找到自己机器的公网接口。为此，请键入：\n1  ip route list default   您的公共接口是在此命令的输出中找到的跟在单词“dev”之后的字符串。例如，此结果显示名为 的接口eth0，它在下面突出显示：\n1 2  Output default via 159.65.160.1 dev eth0 proto static   当您拥有与默认路由关联的接口时，打开 /etc/ufw/before.rules 文件以添加相关配置：\n1  sudo nano /etc/ufw/before.rules   UFW 规则通常使用该ufw命令添加。before.rules但是，在加载传统 UFW 规则之前，会读取文件中列出的规则并将其放置到位。在文件顶部，添加下面突出显示的行。这将为表中的POSTROUTING链设置默认策略nat并伪装来自 VPN 的任何流量。请记住eth0将以-A POSTROUTING下行中的内容替换为您在上述命令中找到的界面：\n/etc/ufw/before.rules\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # # rules.before # # Rules that should be run before the ufw command line added rules. Custom # rules should be added to one of these chains: # ufw-before-input # ufw-before-output # ufw-before-forward # # START OPENVPN RULES # NAT table rules *nat :POSTROUTING ACCEPT [0:0] # Allow traffic from OpenVPN client to eth0 (change to the interface you discovered!) -A POSTROUTING -s 10.8.0.0/8 -o eth0 -j MASQUERADE COMMIT # END OPENVPN RULES # Don\u0026#39;t delete these required lines, otherwise there will be errors *filter . . .   完成后保存并关闭文件。\n接下来，您需要告诉 UFW 默认情况下也允许转发数据包。为此，请打开 /etc/default/ufw 文件：\n1  sudo nano /etc/default/ufw   在里面，找到DEFAULT_FORWARD_POLICY指令并将值从 更改 DROP 为 ACCEPT ：\n/etc/default/ufw\n1  DEFAULT_FORWARD_POLICY=\u0026#34;ACCEPT\u0026#34;   完成后保存并关闭文件。\n接下来，调整防火墙本身以允许 OpenVPN 的流量。如果您没有更改文件中的端口和协议/etc/openvpn/server.conf，则需要打开 UDP 流量到 port 1194。如果您修改了端口和/或协议，请替换您在此处选择的值。\n如果您在遵循先决条件教程时忘记添加 SSH 端口，请在此处添加：\n1 2  sudo ufw allow 1194/udp sudo ufw allow OpenSSH   注意：如果您使用不同的防火墙或自定义了 UFW 配置，则可能需要添加其他防火墙规则。例如，如果你决定隧道所有的网络流量通过VPN连接，你需要确保端口53流量允许DNS请求，而像港口80和443分别为HTTP和HTTPS流量。如果您在 VPN 上使用了其他协议，那么您还需要为它们添加规则。\n添加这些规则后，禁用并重新启用 UFW 以重新启动它并从您修改的所有文件中加载更改：\n1 2  sudo ufw disable sudo ufw enable   您的服务器现已配置为正确处理 OpenVPN 流量。设置好防火墙规则后，我们可以在服务器上启动 OpenVPN 服务。\n启动 OpenVPN OpenVPN 服务器 OpenVPN 作为 systemd 服务运行，因此我们可以使用 systemctl 它来管理它。我们会将 OpenVPN 配置为在启动时启动，因此只要您的服务器正在运行，您就可以随时连接到您的 VPN。为此，请将 OpenVPN 服务添加到 systemctl：\n1  sudo systemctl -f enable openvpn-server@server.service   然后启动OpenVPN服务：\n1  sudo systemctl start openvpn-server@server.service   使用以下命令仔细检查 OpenVPN 服务是否处于活动状态。您应该active (running)在输出中看到：\n1  sudo systemctl status openvpn-server@server.service   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  Output ● openvpn-server@server.service - OpenVPN service for server Loaded: loaded (/lib/systemd/system/openvpn-server@.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2020-04-29 15:39:59 UTC; 6s ago Docs: man:openvpn(8) https://community.openvpn.net/openvpn/wiki/Openvpn24ManPage https://community.openvpn.net/openvpn/wiki/HOWTO Main PID: 16872 (openvpn) Status: \u0026#34;Initialization Sequence Completed\u0026#34; Tasks: 1 (limit: 1137) Memory: 1.0M CGroup: /system.slice/system-openvpn\\x2dserver.slice/openvpn-server@server.service └─16872 /usr/sbin/openvpn --status /run/openvpn-server/status-server.log --status-version 2 --suppress-timestamps --c\u0026gt; . . . . . . Apr 29 15:39:59 ubuntu-20 openvpn[16872]: Initialization Sequence Completed   我们现在已经完成了 OpenVPN 的服务器端配置。接下来，您将配置您的客户端机器并连接到 OpenVPN 服务器。\n创建客户端配置基础架构(无特殊需求可以跳过) OpenVPN 服务器 为 OpenVPN 客户端创建配置文件可能有些复杂，因为每个客户端都必须有自己的配置，并且每个客户端都必须与服务器配置文件中列出的设置保持一致。这一步不是编写只能在一个客户端上使用的单个配置文件，而是概述了构建客户端配置基础结构的过程，您可以使用它来即时生成配置文件。您将首先创建一个“基本”配置文件，然后构建一个脚本，该脚本将允许您根据需要生成唯一的客户端配置文件、证书和密钥。\n首先创建一个新目录，您将client-configs在之前创建的目录中存储客户端配置文件：\n1  mkdir -p ~/client-configs/files   接下来，将示例客户端配置文件复制到client-configs目录中以用作基本配置：\n1  cp /usr/share/doc/openvpn/examples/sample-config-files/client.conf ~/client-configs/base.conf   使用nano或您喜欢的文本编辑器打开这个新文件：\n1  nano ~/client-configs/base.conf   在里面，找到remote指令。这将客户端指向您的 OpenVPN 服务器地址——您的 OpenVPN 服务器的公共 IP 地址。如果您决定更改 OpenVPN 服务器正在侦听的端口，您还需要更改1194为您选择的端口：\n~/client-configs/base.conf\n1 2 3 4 5 6  . . . # The hostname/IP and port of the server. # You can have multiple remote entries # to load balance between the servers. remote your_server_ip 1194 . . .   确保协议与您在服务器配置中使用的值匹配：\n~/client-configs/base.conf\n1  proto udp   接下来，通过删除每行开头的符号来取消对userandgroup指令的注释;：\n~/client-configs/base.conf\n1 2 3  # Downgrade privileges after initialization (non-Windows only) user nobody group nogroup   查找设置的指示ca，cert和key。注释掉这些指令，因为您很快就会在文件本身中添加证书和密钥：\n~/client-configs/base.conf\n1 2 3 4 5 6 7 8 9  # SSL/TLS parms. # See the server config file for more # description. It\u0026#39;s best to use # a separate .crt/.key file pair # for each client. A single ca # file can be used for all clients. ;ca ca.crt ;cert client.crt ;key client.key   同样，注释掉该tls-auth指令，因为您将ta.key直接添加到客户端配置文件中（并且服务器设置为使用tls-crypt）：\n~/client-configs/base.conf\n1 2 3  # If a tls-auth key is used on the server # then every client must also have the key. ;tls-auth ta.key 1   镜像您在文件中设置的cipher和auth设置/etc/openvpn/server/server.conf：\n~/client-configs/base.conf\n1 2  cipher AES-256-GCM auth SHA256   接下来，key-direction在文件中的某处添加指令。您必须将其设置为“1”才能使 VPN 在客户端计算机上正常运行：\n~/client-configs/base.conf\n1  key-direction 1   最后，添加一些注释掉的行来处理基于 Linux 的 VPN 客户端将用于 DNS 解析的各种方法。您将添加两个相似但单独的注释行集。第一组用于不用于systemd-resolved管理 DNS 的客户端。这些客户端依靠该resolvconf实用程序来更新 Linux 客户端的 DNS 信息。\n~/client-configs/base.conf\n1 2 3  ; script-security 2 ; up /etc/openvpn/update-resolv-conf ; down /etc/openvpn/update-resolv-conf   现在为systemd-resolved用于 DNS 解析的客户端添加另一组行：\n~/client-configs/base.conf\n1 2 3 4 5  ; script-security 2 ; up /etc/openvpn/update-systemd-resolved ; down /etc/openvpn/update-systemd-resolved ; down-pre ; dhcp-option DOMAIN-ROUTE .   完成后保存并关闭文件。\n接下来，我们将创建一个脚本，该脚本将使用相关的证书、密钥和加密文件编译您的基本配置，然后将生成的配置放在~/client-configs/files目录中。打开make_config.sh在~/client-configs目录中调用的新文件：\n1  nano ~/client-configs/make_config.sh   在里面，添加以下内容：\n~/client-configs/make_config.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/bash  # First argument: Client identifier KEY_DIR=~/client-configs/keys OUTPUT_DIR=~/client-configs/files BASE_CONFIG=~/client-configs/base.conf cat ${BASE_CONFIG} \\  \u0026lt;(echo -e \u0026#39;\u0026lt;ca\u0026gt;\u0026#39;) \\  ${KEY_DIR}/ca.crt \\  \u0026lt;(echo -e \u0026#39;\u0026lt;/ca\u0026gt;\\n\u0026lt;cert\u0026gt;\u0026#39;) \\  ${KEY_DIR}/.crt \\  \u0026lt;(echo -e \u0026#39;\u0026lt;/cert\u0026gt;\\n\u0026lt;key\u0026gt;\u0026#39;) \\  ${KEY_DIR}/.key \\  \u0026lt;(echo -e \u0026#39;\u0026lt;/key\u0026gt;\\n\u0026lt;tls-crypt\u0026gt;\u0026#39;) \\  ${KEY_DIR}/ta.key \\  \u0026lt;(echo -e \u0026#39;\u0026lt;/tls-crypt\u0026gt;\u0026#39;) \\  \u0026gt; ${OUTPUT_DIR}/.ovpn   完成后保存并关闭文件。\n在继续之前，请确保通过键入以下内容将此文件标记为可执行文件：\n1  chmod 700 ~/client-configs/make_config.sh   此脚本将复制base.conf您创建的文件，收集您为客户端创建的所有证书和密钥文件，提取它们的内容，将它们附加到基本配置文件的副本，并将所有这些内容导出到新的客户端配置文件。这意味着，不必单独管理客户端的配置、证书和密钥文件，所有需要的信息都存储在一个地方。使用此方法的好处是，如果您将来需要添加客户端，您可以运行此脚本来快速创建一个新的配置文件，并确保所有重要信息都存储在一个易于访问的单个地点。\n请注意，每次添加新客户端时，您都需要为其生成新的密钥和证书，然后才能运行此脚本并生成其配置文件。您将在下一步中练习使用此脚本。\n生成客户端配置 生成配置文件：\n1 2  cd ~/client-configs ./make_config.sh client1   这将client1.ovpn在您的~/client-configs/files目录中创建一个名为的文件：\n1  ls ~/client-configs/files   1 2  Output client1.ovpn   您需要将此文件传输到您计划用作客户端的设备。例如，这可能是您的本地计算机或移动设备。\n虽然用于完成此传输的确切应用程序取决于您设备的操作系统和您的个人偏好，但可靠且安全的方法是在后端使用 SFTP（SSH 文件传输协议）或 SCP（安全复制）。这将通过加密连接传输您客户端的 VPN 身份验证文件。\n这是一个示例 SFTP 命令，您可以从本地计算机（macOS 或 Linux）运行该命令。这会将client1.ovpn我们在上一步中创建的文件复制到您的主目录：\n1 2  # sftp sammy@openvpn_server_ip:client-configs/files/client1.ovpn ~/ sftp sammy@123.125.32.26:client-configs/files/client1.ovpn ~/   安装客户端配置 离线安装\n1 2  # ubuntu20.04 系统 sudo dpkg -i pkg/ubuntu20.04/openvpn_2.4.7-1ubuntu2.20.04.4_amd64.deb   1 2  # redhat8.6 系统 sudo rpm -i pkg/redhat8.6/pkg/*   在线安装\n如果您使用的是 Linux，则可以根据您的发行版使用多种工具。您的桌面环境或窗口管理器可能还包括连接实用程序。\n然而，最通用的连接方式是使用 OpenVPN 软件。\n在 Ubuntu 或 Debian 上，您可以像在服务器上一样通过键入以下内容来安装它：\n1 2  sudo apt update sudo apt install openvpn   在 CentOS 上，您可以启用 EPEL 存储库，然后键入以下内容进行安装：\n1 2  sudo dnf install epel-release sudo dnf install openvpn   配置使用的客户端 systemd-resolved 首先systemd-resolved通过检查/etc/resolv.conf文件来确定您的系统是否用于处理 DNS 解析：\n1  cat /etc/resolv.conf   1 2 3 4 5 6  Output # This file is managed by man:systemd-resolved(8). Do not edit. . . . nameserver 127.0.0.53 options edns0   如果您的系统配置为systemd-resolved用于 DNS 解析，则nameserver选项后面的 IP 地址将为127.0.0.53. 文件中还应该有注释，如显示的输出，解释如何systemd-resolved管理文件。如果您有一个不同的 IP 地址，127.0.0.53那么您的系统可能没有使用systemd-resolved，您可以转至下一节配置具有update-resolv-conf脚本的Linux 客户端。\n要支持这些客户端，请首先安装该openvpn-systemd-resolved软件包。它提供了强制systemd-resolved使用 VPN 服务器进行 DNS 解析的脚本。\n1  sudo apt install openvpn-systemd-resolved   安装该软件包之一，配置客户端以使用它，并通过 VPN 接口发送所有 DNS 查询。打开客户端的 VPN 文件：\n1  nano client1.ovpn   现在取消注释您之前添加的以下几行：\nclient1.ovpn\n1 2 3 4 5  script-security 2 up /etc/openvpn/update-systemd-resolved down /etc/openvpn/update-systemd-resolved down-pre dhcp-option DOMAIN-ROUTE .   配置使用的客户端 update-resolv-conf 如果您的系统不systemd-resolved用于管理 DNS，请检查您的发行版是否包含/etc/openvpn/update-resolv-conf脚本：\n1  ls /etc/openvpn   1 2  Output update-resolv-conf   如果您的客户端包含该update-resolv-conf文件，请编辑您之前传输的 OpenVPN 客户端配置文件：\n1  nano client1.ovpn   取消注释您添加的用于调整 DNS 设置的三行：\nclient1.ovpn\n1 2 3  script-security 2 up /etc/openvpn/update-resolv-conf down /etc/openvpn/update-resolv-conf   如果您使用 CentOS，请将group指令从nogroupto更改nobody为匹配发行版的可用组：\nclient1.ovpn\n1  group nobody   保存并关闭文件。\n连接\n现在，您只需将openvpn命令指向客户端配置文件即可连接到 VPN ：\n1 2  # 启动前注意检查 client1.ovpn 的 62 行。在 Ubuntu 系统上是 group nogroup，在 CentOS 系统上是 group nobody sudo openvpn --config client1.ovpn   这应该将您连接到您的 VPN。\n**注意：**如果您的客户端用于systemd-resolved管理 DNS，请通过运行如下systemd-resolve --status命令检查设置是否正确应用：\n1  systemd-resolve --status tun0   1 2 3 4 5 6  Output Link 22 (tun0) . . . DNS Servers: 208.67.222.222 208.67.220.220 DNS Domain: ~.   如果您看到您在 OpenVPN 服务器上配置的 DNS 服务器的 IP 地址，以及输出中DNS 域的~.设置，那么您已正确配置您的客户端以使用 VPN 服务器的 DNS 解析器。\n撤销客户端证书 有时，您可能需要撤销客户端证书以防止进一步访问 OpenVPN 服务器。\nCA 服务器 1 2  cd ~/easy-rsa ./easyrsa revoke client1   这将要求您通过输入 yes 来确认撤销:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  Output Please confirm you wish to revoke the certificate with the following subject: subject= commonName = client-ccx Type the word \u0026#39;yes\u0026#39; to continue, or any other input to abort. Continue with revocation: yes Using configuration from /home/sammy/easy-rsa/pki/safessl-easyrsa.cnf Revoking Certificate D3060496FB55BF756C970DF564AA4C17. Data Base Updated IMPORTANT!!! Revocation was successful. You must run gen-crl and upload a CRL to your infrastructure in order to prevent the revoked cert from being accepted.   注意撤销证书行上突出显示的值。此值是要撤销的证书的唯一序列号。如果要检查本节最后一步中的撤销列表以验证证书是否在其中，则需要此值。\n在确认操作之后，CA 将撤销证书。但是，依赖 CA 的远程系统无法检查是否有任何证书被撤销。用户和服务器仍然可以使用该证书，直至该证书的证书吊销列表(CRL)分发给所有依赖该证书的系统为止。\n生成一个证书吊销列表\n在 ~/easy-rsa 目录中使用 gen-CRL 选项运行 easy-rsa 命令:\n1 2  cd ~/easy-rsa ./easyrsa gen-crl   发送证书吊销列表\n1 2  # scp ~/easy-rsa/pki/crl.pem sammy@your_server_ip:/tmp scp ~/easy-rsa/pki/crl.pem sammy@123.125.32.26:/tmp   OpenVPN 服务器 使用这些说明撤销客户端证书后，您需要将生成的 crl.pem 文件复制到 /etc/openvpn/server 目录中的 OpenVPN 服务器：\n1  sudo cp /tmp/crl.pem /etc/openvpn/server/   接下来，打开 OpenVPN 服务器配置文件:\n1  sudo nano /etc/openvpn/server/server.conf   在文件底部，添加 crl-verify 选项，该选项将指示 OpenVPN 服务器在每次尝试连接时检查您创建的证书吊销列表：\n/etc/openvpn/server/server.conf\n1  crl-verify crl.pem   保存并关闭文件。 最后，重新启动 OpenVPN 以实现证书撤销:\n1  sudo systemctl restart openvpn-server@server.service   客户端应该不再能够使用旧凭据成功连接到服务器。 要撤销其他客户端，请按照以下流程操作：\n 使用 ./easyrsa revoke client_name 命令撤销证书 生成新的 CRL 将新的 crl.pem 文件传输到您的 OpenVPN 服务器并将其复制到 /etc/openvpn/server/ 目录以覆盖旧列表。 重新启动 OpenVPN 服务。  您可以使用此过程撤销您之前为服务器颁发的任何证书。\n配置更多客户端 修改 client1 为你要的客户端名称\nOpenVPN 服务器 到 EasyRSA 目录并 easyrsa 使用gen-req 和 nopass 选项以及客户端的通用名称运行脚本：\n1 2  cd ~/easy-rsa ./easyrsa gen-req client1 nopass   按 ENTER 确认常用名称。然后，将 client1.key 文件复制到 ~/client-configs/keys/ 您之前创建的目录中：\n1  cp pki/private/client1.key ~/client-configs/keys/   CA 服务器 现在登录到您的 CA 服务器。\n接下来，将 client1.req 使用安全方法将文件传输到您的 CA 服务器：\n1 2  # scp sammy@your_openvpn_server_ip:/home/sammy/easy-rsa/pki/reqs/client1.req /tmp scp sammy@123.125.32.26:/home/sammy/easy-rsa/pki/reqs/client1.req /tmp   然后，导航到 EasyRSA 目录，并导入证书请求：\n1 2 3  cd ~/easy-rsa ./easyrsa import-req /tmp/client1.req client1 ./easyrsa sign-req client client1   出现提示时，输入 ye s以确认您打算签署证书请求并且它来自受信任的来源：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  Output Note: using Easy-RSA configuration from: ./vars Using SSL: openssl OpenSSL 1.1.1f 31 Mar 2020 You are about to sign the following certificate. Please check over the details shown below for accuracy. Note that this request has not been cryptographically verified. Please be sure it came from a trusted source or that you have verified the request checksum with the sender. Request subject, to be signed as a client certificate for 1080 days: subject= commonName = client1 Type the word \u0026#39;yes\u0026#39; to continue, or any other input to abort. Confirm request details: yes Using configuration from /home/sammy/easy-rsa/pki/safessl-easyrsa.cnf Check that the request matches the signature Signature ok The Subject\u0026#39;s Distinguished Name is as follows commonName :ASN.1 12:\u0026#39;client1\u0026#39; Certificate is to be certified until Jul 6 06:18:09 2025 GMT (1080 days) Write out database with 1 new entries Data Base Updated Certificate created at: /home/sammy/easy-rsa/pki/issued/client1.crt   这将创建一个名为 client1.crt 将此文件传输回服务器：\n1 2  # scp pki/issued/client1.crt sammy@your_server_ip:/tmp scp pki/issued/client1.crt sammy@123.125.32.26:/tmp   OpenVPN 服务器 回到您的 OpenVPN 服务器，将客户端证书复制到~/client-configs/keys/目录：\n1  cp /tmp/client1.crt ~/client-configs/keys/   生成配置文件：\n1 2  cd ~/client-configs ./make_config.sh client1   这将client1.ovpn在您的~/client-configs/files目录中创建一个名为的文件：\n1  ls ~/client-configs/files   1 2  Output client1.ovpn   您需要将此文件传输到您计划用作客户端的设备。例如，这可能是您的本地计算机或移动设备。\n1 2  # sftp sammy@openvpn_server_ip:client-configs/files/client1.ovpn ~/ sftp sammy@123.125.32.26:client-configs/files/client1.ovpn ~/   安装客户端配置 离线安装\n1 2  # ubuntu20.04 系统 sudo dpkg -i pkg/ubuntu20.04/openvpn_2.4.7-1ubuntu2.20.04.4_amd64.deb   1 2  # redhat8.6 系统 sudo rpm -i pkg/redhat8.6/pkg/*   在线安装\n如果您使用的是 Linux，则可以根据您的发行版使用多种工具。您的桌面环境或窗口管理器可能还包括连接实用程序。\n然而，最通用的连接方式是使用 OpenVPN 软件。\n在 Ubuntu 或 Debian 上，您可以像在服务器上一样通过键入以下内容来安装它：\n1 2  sudo apt update sudo apt install openvpn   在 CentOS 上，您可以启用 EPEL 存储库，然后键入以下内容进行安装：\n1 2  sudo dnf install epel-release sudo dnf install openvpn   配置使用的客户端 systemd-resolved 首先systemd-resolved通过检查/etc/resolv.conf文件来确定您的系统是否用于处理 DNS 解析：\n1  cat /etc/resolv.conf   1 2 3 4 5 6  Output # This file is managed by man:systemd-resolved(8). Do not edit. . . . nameserver 127.0.0.53 options edns0   如果您的系统配置为systemd-resolved用于 DNS 解析，则nameserver选项后面的 IP 地址将为127.0.0.53. 文件中还应该有注释，如显示的输出，解释如何systemd-resolved管理文件。如果您有一个不同的 IP 地址，127.0.0.53那么您的系统可能没有使用systemd-resolved，您可以转至下一节配置具有update-resolv-conf脚本的Linux 客户端。\n要支持这些客户端，请首先安装该openvpn-systemd-resolved软件包。它提供了强制systemd-resolved使用 VPN 服务器进行 DNS 解析的脚本。\n1  sudo apt install openvpn-systemd-resolved   安装该软件包之一，配置客户端以使用它，并通过 VPN 接口发送所有 DNS 查询。打开客户端的 VPN 文件：\n1  nano client1.ovpn   现在取消注释您之前添加的以下几行：\nclient1.ovpn\n1 2 3 4 5  script-security 2 up /etc/openvpn/update-systemd-resolved down /etc/openvpn/update-systemd-resolved down-pre dhcp-option DOMAIN-ROUTE .   配置使用的客户端 update-resolv-conf 如果您的系统不systemd-resolved用于管理 DNS，请检查您的发行版是否包含/etc/openvpn/update-resolv-conf脚本：\n1  ls /etc/openvpn   1 2  Output update-resolv-conf   如果您的客户端包含该update-resolv-conf文件，请编辑您之前传输的 OpenVPN 客户端配置文件：\n1  nano client1.ovpn   取消注释您添加的用于调整 DNS 设置的三行：\nclient1.ovpn\n1 2 3  script-security 2 up /etc/openvpn/update-resolv-conf down /etc/openvpn/update-resolv-conf   如果您使用 CentOS，请将group指令从nogroupto更改nobody为匹配发行版的可用组：\nclient1.ovpn\n1  group nobody   保存并关闭文件。\n连接\n现在，您只需将openvpn命令指向客户端配置文件即可连接到 VPN ：\n1 2  # 启动前注意检查 client1.ovpn 的 62 行。在 Ubuntu 系统上是 group nogroup，在 CentOS 系统上是 group nobody sudo openvpn --config client1.ovpn   这应该将您连接到您的 VPN。\n**注意：**如果您的客户端用于systemd-resolved管理 DNS，请通过运行如下systemd-resolve --status命令检查设置是否正确应用：\n1  systemd-resolve --status tun0   1 2 3 4 5 6  Output Link 22 (tun0) . . . DNS Servers: 208.67.222.222 208.67.220.220 DNS Domain: ~.   如果您看到您在 OpenVPN 服务器上配置的 DNS 服务器的 IP 地址，以及输出中DNS 域的~.设置，那么您已正确配置您的客户端以使用 VPN 服务器的 DNS 解析器。\n安装 OpenVPN 客户端配置 离线安装\n1  sudo rpm -i pkg/redhat8.6/pkg/*   配置文件\n xxx-master.ovpn: 在 master 节点使用，会固定 VPN 的 IP，只能单节点使用。 xxx-worker.ovpn: 在 worker 节点使用，不会固定 VPN 的 IP，可以多节点使用。  配置使用\n 如果客户端需要固定端口的情况才操作，一般情况忽略。固定客户端端口：修改 xxx.ovpn 第 58 行，nobind -\u0026gt; port 51194\n 设置 systemctl 管理\n1 2 3 4 5 6 7 8  # 复制文件 sudo cp xxx.ovpn /etc/openvpn/client/client.conf # 开机启动 systemctl enable openvpn-client@client # 启动 systemctl start openvpn-client@client # 停止 systemctl stop openvpn-client@client   测试\n1 2  systemctl status openvpn-client@client ping 10.10.0.1   其它设置 客户端固定端口 修改 client1.ovpn 第 58 行，nobind -\u0026gt; port 51194\n设置 systemctl 启动 1 2 3 4 5 6 7 8 9 10 11  sudo cp client1.ovpn /etc/openvpn/client/client.conf # 开机启动 systemctl enable openvpn-client@client # 启动 systemctl start openvpn-client@client # 停止 systemctl stop openvpn-client@client # 测试 systemctl status openvpn-client@client ping 10.8.0.1   固定客户端 IP 1 2 3 4  # openvpn 服务器 vi /etc/openvpn/server/server.conf # 添加一行 client-config-dir /etc/openvpn/ccd   在 /etc/openvpn/ccd 创建文件，文件名为客户端的 CN 名称，内容为ifconfig-push ${IP} ${NETMASK}\n样例：\n1 2 3 4 5 6 7  sammy@OpenVPN:/etc/openvpn/ccd$ ll total 12 drwxr-xr-x 2 root root 4096 Aug 22 15:50 ./ drwxr-xr-x 5 root root 4096 Aug 22 15:19 ../ -rw-r--r-- 1 root root 35 Aug 22 15:50 tx-cjx-master sammy@OpenVPN:/etc/openvpn/ccd$ cat tx-cjx-master ifconfig-push 10.8.0.100 10.8.0.99   效果 在开启了允许客户端证书复用的情况下。固定了 IP 的证书被重复使用时，只有最后一个使用者可以连接到服务器，IP 固定。 未固定 IP 的证书可以正常复用。\n安装 OpenVPN 客户端配置 离线安装\n1  sudo rpm -i pkg/redhat8.6/pkg/*   配置文件\n xxx-master.ovpn: 在 master 节点使用，会固定 VPN 的 IP，只能单节点使用。 xxx-worker.ovpn: 在 worker 节点使用，不会固定 VPN 的 IP，可以多节点使用。  配置使用\n 如果客户端需要固定端口的情况才操作，一般情况忽略。固定客户端端口：修改 xxx.ovpn 第 58 行，nobind -\u0026gt; port 51194\n 设置 systemctl 管理\n1 2 3 4 5 6 7 8  # 复制文件 sudo cp xxx.ovpn /etc/openvpn/client/client.conf # 开机启动 systemctl enable openvpn-client@client # 启动 systemctl start openvpn-client@client # 停止 systemctl stop openvpn-client@client   测试\n1 2  systemctl status openvpn-client@client ping 10.10.0.1   ","date":"2020-08-06T00:00:00Z","permalink":"https://mkbooks.github.io/blog/p/%E5%9C%A8-ubuntu20.04-%E5%BB%BA%E8%AE%BE-openvpn/","title":"在 Ubuntu20.04 建设 openVPN"}]